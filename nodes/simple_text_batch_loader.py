#!/usr/bin/env python3
"""
ç®€åŒ–æ–‡æœ¬æ‰¹é‡åŠ è½½å™¨
åŸºäºæ™ºèƒ½æ–‡æœ¬æ‰¹é‡åŠ è½½å™¨çš„é€»è¾‘ï¼Œæä¾›ç®€æ´çš„æ‰¹é‡æ–‡æœ¬åŠ è½½åŠŸèƒ½
"""

import os
import random
import re
import time
from pathlib import Path
from typing import List, Dict, Any, Tuple, Union

class buding_SimpleTextBatchLoader:
    """ç®€åŒ–æ–‡æœ¬æ‰¹é‡åŠ è½½å™¨"""
    
    # ç±»çº§åˆ«ç¼“å­˜ï¼šå­˜å‚¨ç›®å½•æ‰«æç»“æœ
    _scan_cache = {}  # {"directory_path": {"files": [...], "timestamp": time}}
    
    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰è¾“å…¥å‚æ•°"""
        inputs = {
            "required": {
                "directory_path": ("STRING", {"default": "", "tooltip": "æ–‡æœ¬æ–‡ä»¶æ‰€åœ¨ç›®å½•è·¯å¾„"}),
                "file_extension": (
                    [".txt", ".srt", ".vtt", ".ass", ".ssa", "ä»»æ„æ–‡ä»¶"], 
                    {"default": ".txt", "tooltip": "æ–‡ä»¶æ‰©å±•åè¿‡æ»¤ï¼Œé€‰æ‹©'ä»»æ„æ–‡ä»¶'åŒ¹é…æ‰€æœ‰æ–‡æœ¬ç±»æ–‡ä»¶"}
                ),
                "positive_keywords": ("STRING", {"default": "", "multiline": True, "tooltip": "æ­£å‘ç­›é€‰å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ª"}),
                "positive_input_mode": (["åŒ…å«åŒ¹é…", "ç²¾ç¡®åŒ¹é…", "æ­£åˆ™è¡¨è¾¾å¼"], {"default": "åŒ…å«åŒ¹é…", "tooltip": "æ­£å‘å…³é”®è¯åŒ¹é…æ¨¡å¼"}),
                "max_files": ("INT", {"default": 100, "min": 1, "max": 1000, "step": 1, "tooltip": "æœ€å¤§åŠ è½½æ–‡ä»¶æ•°é‡"}),
                "start_index": ("INT", {"default": 0, "min": 0, "step": 1, "tooltip": "ä»åˆ—è¡¨çš„å“ªä¸ªç´¢å¼•å¼€å§‹"}),
                "always_reload": ("BOOLEAN", {"default": False, "tooltip": "å¼€å¯åå§‹ç»ˆé‡æ–°åŠ è½½ï¼Œä¸ä½¿ç”¨ç¼“å­˜"}),
                "similarity_threshold": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.1, "tooltip": "æ¨¡ç³ŠåŒ¹é…åº¦é˜ˆå€¼"}),
                "scan_max_depth": ("INT", {"default": 5, "min": 1, "max": 20, "step": 1, "tooltip": "ç›®å½•æ‰«ææœ€å¤§æ·±åº¦"}),
                "enable_negative_enhance": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨åå‘å…³é”®è¯å¢å¼ºåŒ¹é…"}),
                "negative_keywords": ("STRING", {"default": "", "multiline": True, "tooltip": "åå‘æ’é™¤å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ª"}),
                "sort_mode": (["æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)", "æ–‡ä»¶å(å­—æ¯)", "ä¿®æ”¹æ—¶é—´(æ–°åˆ°æ—§)", "ä¿®æ”¹æ—¶é—´(æ—§åˆ°æ–°)", "éšæœºæ’åº"], {"default": "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)", "tooltip": "æ–‡ä»¶æ’åºæ–¹å¼"}),
                "debug_mode": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨è°ƒè¯•è¾“å‡º"}),
                "mode": (["æ‰¹é‡", "å•é€‰"], {"default": "æ‰¹é‡", "tooltip": "é€‰æ‹©è¾“å‡ºæ¨¡å¼ï¼šæ‰¹é‡è¿”å›æ•´æ‰¹æ–‡ä»¶ï¼Œå•é€‰åªè¿”å›force_select_indexæŒ‡å®šçš„æ–‡ä»¶"}),
                "force_select_index": ("INT", {"default": 0, "min": 0, "step": 1, "tooltip": "å•é€‰æ¨¡å¼ä¸‹çš„æ–‡ä»¶ç´¢å¼•ï¼Œä»0å¼€å§‹"}),
                "random_selection": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦éšæœºé€‰æ‹©æ–‡ä»¶"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xFFFFFFFFFFFFFFFF, "tooltip": "éšæœºç§å­ï¼Œ0è¡¨ç¤ºè‡ªåŠ¨ç”Ÿæˆ"}),
            }
        }
        return inputs
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("text_content_list", "merged_text_content", "file_paths", "load_log")
    OUTPUT_IS_LIST = (True, False, True, False)  # file_pathsä¹Ÿè¿”å›åˆ—è¡¨æ ¼å¼ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
    FUNCTION = "load_text_batch"
    CATEGORY = "buding_Tools/ç®€åŒ–æ–‡æœ¬åŠ è½½"
    DESCRIPTION = "ç®€åŒ–ç‰ˆæ–‡æœ¬æ‰¹é‡åŠ è½½å™¨ï¼ŒåŸºäºSmartTextLoaderé€»è¾‘"
    
    @classmethod
    def IS_CHANGED(cls, directory_path, file_extension, positive_keywords, positive_input_mode,
                   max_files, start_index, always_reload, similarity_threshold,
                   scan_max_depth, enable_negative_enhance, negative_keywords, sort_mode,
                   debug_mode, mode, force_select_index, random_selection, seed):
        """æ£€æŸ¥è¾“å…¥æ˜¯å¦æ”¹å˜ - å®Œæ•´åŒ…å«æ‰€æœ‰ä¼šå½±å“è¾“å‡ºçš„å‚æ•°"""
        if always_reload:
            return float("nan")  # å¼ºåˆ¶é‡æ–°åŠ è½½
        
        # ä½¿ç”¨frozensetç¡®ä¿åŒ…å«æ‰€æœ‰å½±å“è¾“å‡ºçš„å‚æ•°ï¼Œå‚æ•°é¡ºåºä¸å½±å“å“ˆå¸Œå€¼
        key_params = {
            'directory_path': directory_path,
            'file_extension': file_extension,
            'positive_keywords': positive_keywords,
            'positive_input_mode': positive_input_mode,
            'max_files': max_files,
            'start_index': start_index,
            'similarity_threshold': similarity_threshold,
            'scan_max_depth': scan_max_depth,
            'enable_negative_enhance': enable_negative_enhance,
            'negative_keywords': negative_keywords,
            'sort_mode': sort_mode,
            'mode': mode,
            'force_select_index': force_select_index,
            'random_selection': random_selection,
            'seed': seed,
        }
        return hash(frozenset(key_params.items()))
    
    def load_text_batch(self, directory_path: str, file_extension: str, positive_keywords: str,
                        positive_input_mode: str, max_files: int, start_index: int,
                        always_reload: bool, similarity_threshold: float,
                        scan_max_depth: int, enable_negative_enhance: bool, negative_keywords: str,
                        sort_mode: str, debug_mode: bool, mode: str, force_select_index: int,
                        random_selection: bool, seed: int) -> Tuple[List[str], str, List[str], str]:
        """åŠ è½½æ–‡æœ¬æ‰¹é‡æ–‡ä»¶"""
        
        # æ¸…ç†è·¯å¾„
        directory_path = directory_path.strip().strip('"\'')
        current_time_str = time.strftime("%Y-%m-%d %H:%M")
        
        if not directory_path or not os.path.exists(directory_path):
            status = "ğŸ“„ âŒ åŠ è½½å¤±è´¥ï¼šç›®å½•ä¸å­˜åœ¨"
            log = f"{status}\nç›®å½•: {directory_path}\næ—¶é—´: {current_time_str}"
            if debug_mode:
                print(f"âŒ {status}: {directory_path}")
            return [], "", [], log
        
        # è®¾ç½®éšæœºç§å­
        if random_selection and seed > 0:
            random.seed(seed)
        
        try:
            # 1. æ‰«ææˆ–è·å–ç¼“å­˜çš„æ–‡æœ¬æ–‡ä»¶
            text_files = self._get_cached_file_list(directory_path, file_extension, scan_max_depth, debug_mode)
            
            if debug_mode:
                print(f"ğŸ“ æ‰«æå®Œæˆ: æ‰¾åˆ° {len(text_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶")
            
            if not text_files:
                status = "ğŸ“„ âŒ åŠ è½½å¤±è´¥ï¼šæœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ (è¯·æ£€æŸ¥åç¼€)"
                log = f"{status}\nç›®å½•: {directory_path}\næ—¶é—´: {current_time_str}"
                return [], "", [], log
            
            # 2. å…³é”®è¯ç­›é€‰
            filtered_files = self._filter_by_keywords(text_files, positive_keywords, 
                                                     positive_input_mode, similarity_threshold, 
                                                     debug_mode)
            
            if debug_mode:
                print(f"ğŸ” æ­£å‘ç­›é€‰å: {len(filtered_files)} ä¸ªæ–‡ä»¶")
            
            if not filtered_files:
                status = "ğŸ“„ âŒ åŠ è½½å¤±è´¥ï¼šæœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ (è¯·æ£€æŸ¥å…³é”®è¯)"
                log = f"{status}\nç›®å½•: {directory_path}\næ—¶é—´: {current_time_str}"
                return [], "", [], log
            
            # 3. åå‘å…³é”®è¯å¢å¼ºåŒ¹é…
            if enable_negative_enhance and negative_keywords.strip():
                filtered_files = self._apply_negative_filter(filtered_files, negative_keywords, debug_mode)
                
                if debug_mode:
                    print(f"ğŸš« åå‘ç­›é€‰å: {len(filtered_files)} ä¸ªæ–‡ä»¶")
            
            # 4. æ’åº
            filtered_files = self._sort_files(filtered_files, sort_mode, debug_mode)
            
            # 5. éšæœºé€‰æ‹©
            if random_selection:
                if seed == 0:
                    seed = random.randint(0, 0xFFFFFFFFFFFFFFFF)
                    random.seed(seed)
                random.shuffle(filtered_files)
                
                if debug_mode:
                    print(f"ğŸ² éšæœºæ’åºå®Œæˆï¼Œç§å­: {seed}")
            
            # 6. è®¾ç½®é»˜è®¤é€‰ä¸­ç´¢å¼•ï¼ˆç”¨äºæ‰¹é‡æ¨¡å¼çš„é¢„è§ˆï¼‰
            selected_index = start_index
            if force_select_index >= 0 and force_select_index < len(filtered_files):
                selected_index = force_select_index
            elif start_index >= len(filtered_files):
                selected_index = max(0, len(filtered_files) - 1)
            
            # 7. åŠ è½½æ–‡æœ¬å†…å®¹
            text_contents, file_paths = self._load_text_contents(filtered_files, debug_mode)
            
            if not text_contents:
                status = "ğŸ“„ âŒ åŠ è½½å¤±è´¥ï¼šæ— æ³•è¯»å–æ–‡æœ¬æ–‡ä»¶"
                log = f"{status}\nç›®å½•: {directory_path}\næ—¶é—´: {current_time_str}"
                return [], "", [], log
            
            # 8. æ ¹æ®æ¨¡å¼å¤„ç†è¾“å‡º
            if mode == "å•é€‰":
                # å•é€‰æ¨¡å¼ï¼šåªè¿”å›force_select_indexæŒ‡å®šçš„æ–‡ä»¶
                selected_index = min(force_select_index, len(text_contents) - 1) if text_contents else 0
                selected_content = text_contents[selected_index] if text_contents else ""
                selected_path = file_paths[selected_index] if file_paths else ""
                
                # æ‰€æœ‰è¾“å‡ºéƒ½é’ˆå¯¹å•ä¸ªæ–‡ä»¶
                result_contents = [selected_content] if selected_content else []
                result_merged = selected_content
                result_paths = [selected_path] if selected_path else []
                result_count = 1
                
                if debug_mode:
                    print(f"ğŸ¯ å•é€‰æ¨¡å¼ï¼šé€‰ä¸­ç¬¬{selected_index}ä¸ªæ–‡ä»¶")
                    print(f"ğŸ“„ è¿”å›è·¯å¾„ï¼š{selected_path}")
                    
            else:  # æ‰¹é‡æ¨¡å¼
                # æ‰¹é‡æ¨¡å¼ï¼šå…ˆåº”ç”¨start_indexåˆ‡ç‰‡ï¼Œå†é™åˆ¶max_filesæ•°é‡
                result_contents = text_contents
                result_paths = file_paths
                
                # å…ˆåº”ç”¨start_indexåˆ‡ç‰‡
                if start_index > 0:
                    if start_index < len(result_contents) and start_index < len(result_paths):
                        result_contents = result_contents[start_index:]
                        result_paths = result_paths[start_index:]
                    else:
                        # å¦‚æœstart_indexè¶…å‡ºèŒƒå›´ï¼Œè¿”å›ç©º
                        result_contents = []
                        result_paths = []
                
                # å†åº”ç”¨max_filesé™åˆ¶
                if max_files > 0:
                    result_contents = result_contents[:max_files]
                    result_paths = result_paths[:max_files]
                
                result_count = len(result_contents)
                
                # åˆå¹¶æ‰€æœ‰æ–‡æœ¬å†…å®¹
                result_merged = "\n---\n".join(result_contents)
                
                if debug_mode:
                    print(f"ğŸ“¦ æ‰¹é‡æ¨¡å¼ï¼šè¿”å› {len(result_contents)} ä¸ªæ–‡æœ¬åˆ—è¡¨")
            
            # ç”ŸæˆæˆåŠŸæ—¥å¿—
            last_filename = os.path.basename(result_paths[-1]) if result_paths else "None"
            log = (
                f"ğŸ“Š æ‰¹é‡åŠ è½½å®Œæˆ | ğŸ”¢ æ€»è®¡: {result_count} ä¸ªæ–‡ä»¶\n"
                f"ğŸ“‚ æ ¹ç›®å½•: {directory_path}\n"
                f"ğŸ”š ç»“æŸäº: {last_filename}\n"
                f"ğŸ•’ æ—¶é—´: {current_time_str}"
            )
            
            # 9. è¿”å›ç»“æœ (ä¸è€èŠ‚ç‚¹æ ¼å¼ä¸€è‡´)
            # è¿”å›æ ¼å¼ï¼š(text_content_list, merged_text_content, file_paths, load_log)
            return result_contents, result_merged, result_paths, log
            
        except Exception as e:
            status = f"ğŸ“„ âŒ åŠ è½½å¤±è´¥ï¼š{str(e)}"
            log = f"{status}\nç›®å½•: {directory_path}\næ—¶é—´: {current_time_str}"
            if debug_mode:
                print(f"âŒ {status}")
                import traceback
                traceback.print_exc()
            return [], "", [], log
    
    def _get_cached_file_list(self, directory_path: str, file_extension: str, max_depth: int, debug_mode: bool) -> List[Dict[str, Any]]:
        """è·å–ç¼“å­˜çš„æ–‡ä»¶åˆ—è¡¨ï¼Œé¿å…é‡å¤æ‰«æå¤§æ–‡ä»¶å¤¹"""
        current_time = time.time()
        cache_key = directory_path
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆ30ç§’å†…æœ‰æ•ˆï¼‰
        if cache_key in self._scan_cache:
            cached = self._scan_cache[cache_key]
            if current_time - cached['timestamp'] < 30:
                if debug_mode:
                    print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜æ–‡ä»¶åˆ—è¡¨ (è·ç¦»ä¸Šæ¬¡æ‰«æ {int(current_time - cached['timestamp'])}s)")
                return cached['files']
        
        # ç¼“å­˜è¿‡æœŸæˆ–ä¸å­˜åœ¨ï¼Œæ‰§è¡Œæ–°æ‰«æ
        files = self._scan_text_files(directory_path, file_extension, max_depth, debug_mode)
        
        # æ›´æ–°ç¼“å­˜
        self._scan_cache[cache_key] = {
            'files': files,
            'timestamp': current_time
        }
        
        if debug_mode:
            print(f"ğŸ”„ ç¼“å­˜å·²æ›´æ–° (æ‰«æ {len(files)} ä¸ªæ–‡ä»¶)")
        
        return files
    
    def _scan_text_files(self, directory_path: str, file_extension: str, max_depth: int, debug_mode: bool) -> List[Dict[str, Any]]:
        """æ‰«ææ–‡æœ¬æ–‡ä»¶ - é‡‡ç”¨ä¹è§‚è¿‡æ»¤ï¼ˆæ‰©å±•åï¼‰,å»¶è¿ŸéªŒè¯åˆ°åŠ è½½é˜¶æ®µ"""
        text_files = []
        
        # å¤„ç†æ–‡ä»¶æ‰©å±•åé€‰é¡¹ (ä¸smart_text_loaderé€»è¾‘ä¸€è‡´)
        if file_extension == "ä»»æ„æ–‡ä»¶":
            extensions = {'.txt', '.srt', '.vtt', '.ass', '.ssa', '.md', '.log', '.csv', '.json', '.xml', '.yaml', '.yml'}
        else:
            extensions = {file_extension.strip().lower()}
        
        def scan_recursive(current_dir: str, current_depth: int):
            if current_depth > max_depth:
                return
            
            try:
                for item in os.listdir(current_dir):
                    item_path = os.path.join(current_dir, item)
                    
                    if os.path.isfile(item_path):
                        # æ£€æŸ¥æ‰©å±•åï¼ˆä¹è§‚è¿‡æ»¤ - O(1) æŸ¥è¯¢ï¼Œä¸æ‰“å¼€æ–‡ä»¶ï¼‰
                        file_ext = os.path.splitext(item)[1].lower()
                        if file_ext not in extensions:
                            continue
                        
                        # ç›´æ¥æ·»åŠ æ–‡ä»¶ä¿¡æ¯ï¼ŒéªŒè¯å»¶è¿Ÿåˆ°åŠ è½½é˜¶æ®µ
                        file_info = {
                            'path': item_path,
                            'filename': item,
                            'mtime': os.path.getmtime(item_path)
                        }
                        text_files.append(file_info)
                    
                    elif os.path.isdir(item_path):
                        scan_recursive(item_path, current_depth + 1)
                        
            except PermissionError:
                if debug_mode:
                    print(f"âš ï¸ æ— æƒé™è®¿é—®ç›®å½•: {current_dir}")
            except Exception as e:
                if debug_mode:
                    print(f"âš ï¸ æ‰«æç›®å½•å‡ºé”™ {current_dir}: {e}")
        
        scan_recursive(directory_path, 0)
        return text_files
    
    def _filter_by_keywords(self, files: List[Dict[str, Any]], keywords: str, mode: str, 
                           threshold: float, debug_mode: bool) -> List[Dict[str, Any]]:
        """ä¼˜åŒ–åçš„å…³é”®è¯ç­›é€‰ï¼šå¿…é¡»æ»¡è¶³æ‰€æœ‰è¡Œï¼ˆAND é€»è¾‘ï¼‰"""
        if not keywords.strip():
            return files
        
        keyword_list = [kw.strip().lower() for kw in keywords.split('\n') if kw.strip()]
        filtered_files = []
        
        for file_info in files:
            filename = file_info['filename'].lower()
            
            # ã€æ ¸å¿ƒä¿®æ”¹ç‚¹ã€‘ï¼šåˆå§‹è®¾ä¸ºåŒ¹é…æˆåŠŸï¼Œå¿…é¡»é€šè¿‡æ¯ä¸€ä¸ªå…³é”®è¯çš„è€ƒéªŒ
            all_keywords_matched = True
            
            for keyword in keyword_list:
                line_matched = False
                
                if mode == "åŒ…å«åŒ¹é…":
                    if keyword in filename:
                        line_matched = True
                elif mode == "ç²¾ç¡®åŒ¹é…":
                    if keyword == filename:
                        line_matched = True
                elif mode == "æ­£åˆ™è¡¨è¾¾å¼":
                    try:
                        if re.search(keyword, filename, re.IGNORECASE):
                            line_matched = True
                    except re.error:
                        pass
                
                # å¦‚æœæœ‰ä¸€ä¸ªå…³é”®è¯æ²¡å¯¹ä¸Šï¼Œå°±åˆ¤æ­»åˆ‘ï¼Œè·³å‡ºå…³é”®è¯å¾ªç¯
                if not line_matched:
                    all_keywords_matched = False
                    break
            
            # åªæœ‰é€šè¿‡äº†æ‰€æœ‰å…³é”®è¯ç­›é€‰çš„æ–‡ä»¶æ‰ä¼šè¢«æ·»åŠ 
            if all_keywords_matched:
                filtered_files.append(file_info)
        
        return filtered_files
    
    def _apply_negative_filter(self, files: List[Dict[str, Any]], negative_keywords: str, debug_mode: bool) -> List[Dict[str, Any]]:
        """åº”ç”¨åå‘å…³é”®è¯è¿‡æ»¤"""
        if not negative_keywords.strip():
            return files
        
        negative_list = [kw.strip().lower() for kw in negative_keywords.split('\n') if kw.strip()]
        filtered_files = []
        
        for file_info in files:
            filename = file_info['filename'].lower()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•åå‘å…³é”®è¯
            is_negative = any(neg_kw in filename for neg_kw in negative_list)
            
            if not is_negative:
                filtered_files.append(file_info)
        
        return filtered_files
    
    def _sort_files(self, files: List[Dict[str, Any]], sort_mode: str, debug_mode: bool) -> List[Dict[str, Any]]:
        """æ’åºæ–‡ä»¶"""
        if not files:
            return files
        
        if sort_mode == "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)":
            def sort_key(item):
                filename = item['filename']
                # æå–æ•°å­—è¿›è¡Œæ’åº
                numbers = re.findall(r'\d+', filename)
                if numbers:
                    return (0, int(numbers[0]), filename.lower())
                else:
                    return (1, 0, filename.lower())
            return sorted(files, key=sort_key)
        
        elif sort_mode == "æ–‡ä»¶å(å­—æ¯)":
            return sorted(files, key=lambda x: x['filename'].lower())
        
        elif sort_mode == "ä¿®æ”¹æ—¶é—´(æ–°åˆ°æ—§)":
            return sorted(files, key=lambda x: x['mtime'], reverse=True)
        
        elif sort_mode == "ä¿®æ”¹æ—¶é—´(æ—§åˆ°æ–°)":
            return sorted(files, key=lambda x: x['mtime'])
        
        elif sort_mode == "éšæœºæ’åº":
            shuffled = files.copy()
            random.shuffle(shuffled)
            return shuffled
        
        else:
            return files
    
    def _load_text_contents(self, files: List[Dict[str, Any]], debug_mode: bool) -> Tuple[List[str], List[str]]:
        """åŠ è½½æ–‡æœ¬æ–‡ä»¶å†…å®¹"""
        text_contents = []
        file_paths = []
        
        for file_info in files:
            file_path = file_info['path']
            try:
                if debug_mode:
                    print(f"ğŸ“ åŠ è½½æ–‡æœ¬: {os.path.basename(file_path)}")
                
                # ä½¿ç”¨æ™ºèƒ½ç¼–ç æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                content = self._read_text_file(file_path, debug_mode)
                
                if content is not None:
                    text_contents.append(content)
                    file_paths.append(file_path)
                
            except Exception as text_error:
                if debug_mode:
                    print(f"âš ï¸ åŠ è½½æ–‡æœ¬å¤±è´¥ï¼Œè·³è¿‡: {os.path.basename(file_path)}, é”™è¯¯: {text_error}")
                continue
        
        return text_contents, file_paths
    
    def _read_text_file(self, file_path: str, debug_mode: bool) -> str:
        """è¯»å–å•ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œä½¿ç”¨æ™ºèƒ½ç¼–ç æ£€æµ‹"""
        encodings_to_try = ['utf-8-sig', 'utf-8', 'gbk', 'utf-16', 'latin-1']
        used_encoding = None
        
        for enc in encodings_to_try:
            try:
                with open(file_path, 'r', encoding=enc) as f:
                    content = f.read()
                    used_encoding = enc
                    break
            except UnicodeDecodeError:
                continue
        
        if used_encoding is None:
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨é”™è¯¯å¤„ç†æ¨¡å¼
            with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
            used_encoding = 'utf-8-replace'
        
        if debug_mode:
            print(f"ğŸ“ è‡ªåŠ¨æ£€æµ‹ç¼–ç : {used_encoding}")
        
        # æ ‡å‡†åŒ–æ¢è¡Œç¬¦
        content = content.replace('\r\n', '\n').replace('\r', '\n')
        
        return content

# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "buding_SimpleTextBatchLoader": buding_SimpleTextBatchLoader,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "buding_SimpleTextBatchLoader": "ğŸ“ ç®€åŒ–æ–‡æœ¬æ‰¹é‡åŠ è½½å™¨",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']
