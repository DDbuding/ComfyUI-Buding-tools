import os
import csv
import random
import time
import re
from pathlib import Path

# å°è¯•å¯¼å…¥ openpyxl ä»¥æ”¯æŒ .xlsx
try:
    import openpyxl
except ImportError:
    print("[buding_Tools] è­¦å‘Š: æœªæ‰¾åˆ° openpyxlï¼Œ.xlsx åŠŸèƒ½å°†å—é™ã€‚è¯·è¿è¡Œ: pip install openpyxl")

# å¯¼å…¥é€šç”¨å·¥å…·å‡½æ•°
# æ³¨æ„ï¼šé€šç”¨å·¥å…·å‡½æ•°ä¸å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨å†…ç½®å®ç°


class buding_SimpleExcelBatchLoader:
    def __init__(self):
        # é»˜è®¤è¾“å‡ºè·¯å¾„è®¾ä¸º ComfyUI çš„ output æ–‡ä»¶å¤¹
        self.comfy_output_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "output")

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "directory_path": ("STRING", {"default": "", "tooltip": "è¦æ‰«æçš„ç›®å½•è·¯å¾„"}),
                "file_type": ([".xlsx", ".csv", ".txt", "all"], {"default": "all", "tooltip": "æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"}),
                "positive_keywords": ("STRING", {"multiline": True, "default": "", "tooltip": "æ­£å‘ç­›é€‰å…³é”®è¯ï¼Œå¤šè¡Œæ–‡æœ¬è¾“å…¥"}),
                "keyword_input_mode": (["å¤šè¡Œæ–‡æœ¬", "å•è¡Œæ–‡æœ¬"], {"default": "å¤šè¡Œæ–‡æœ¬", "tooltip": "æ­£å‘å…³é”®è¯è¾“å…¥æ¨¡å¼"}),
                "keyword_match_mode": (["åŒ…å«åŒ¹é…", "ç²¾ç¡®åŒ¹é…", "æ­£åˆ™è¡¨è¾¾å¼"], {"default": "åŒ…å«åŒ¹é…", "tooltip": "æ­£å‘å…³é”®è¯åŒ¹é…æ¨¡å¼"}),
                "max_files": ("INT", {"default": 1, "min": 1, "tooltip": "æ–‡ä»¶åŠ è½½ä¸Šé™"}),
                "start_index": ("INT", {"default": 0, "min": 0, "tooltip": "èµ·å§‹ç´¢å¼•"}),
                "force_select_index": ("INT", {"default": -1, "min": -1, "tooltip": "å¼ºåˆ¶é€‰æ‹©ç‰¹å®šæ–‡ä»¶ï¼Œ-1è¡¨ç¤ºä¸å¼ºåˆ¶"}),
                "always_reload": ("BOOLEAN", {"default": True, "tooltip": "å§‹ç»ˆé‡æ–°åŠ è½½"}),
                "similarity_threshold": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "tooltip": "æ¨¡ç³ŠåŒ¹é…åº¦é˜ˆå€¼"}),
                "scan_max_depth": ("INT", {"default": 1, "min": 1, "tooltip": "æ‰«ææœ€å¤§æ·±åº¦"}),
                "enable_negative_enhance": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨åå‘å…³é”®è¯å¢å¼ºåŒ¹é…"}),
                "negative_keywords": ("STRING", {"multiline": True, "default": "", "tooltip": "åå‘æ’é™¤å…³é”®è¯"}),
                "sort_mode": (["name", "date_newest", "date_oldest", "size"], {"default": "name", "tooltip": "æ–‡ä»¶æ’åºæ–¹å¼"}),
                "debug_mode": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨è°ƒè¯•æ¨¡å¼"}),
                "random_selection": ("BOOLEAN", {"default": False, "tooltip": "éšæœºé€‰æ‹©å¼€å…³"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff, "tooltip": "éšæœºç§å­"}),
                # --- æ¨¡å¼æ§åˆ¶ ---
                "operation_mode": (["Single (å•é€‰æ¨¡å¼)", "Bulk Merger (åˆå¹¶æ¨¡å¼)"], {"default": "Single (å•é€‰æ¨¡å¼)", "tooltip": "å·¥ä½œæ¨¡å¼é€‰æ‹©"}),
                "output_path": ("STRING", {"default": "", "tooltip": "åˆå¹¶æ¨¡å¼ä¸‹çš„è¾“å‡ºè·¯å¾„ï¼Œç•™ç©ºé»˜è®¤ComfyUI outputç›®å½•"}),
                "overwrite_output": ("BOOLEAN", {"default": True, "tooltip": "æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶"}),
                "generate_merged_text": ("BOOLEAN", {"default": False, "tooltip": "ç”Ÿæˆåˆå¹¶æ–‡æœ¬ï¼ˆæƒ°æ€§ä¼˜åŒ–å¼€å…³ï¼Œé»˜è®¤å…³é—­ï¼‰"}),
            }
        }

    RETURN_TYPES = ("STRING", "LIST", "STRING", "STRING")
    RETURN_NAMES = ("file_path_output", "row_content_list", "merged_text_all", "load_log")
    OUTPUT_IS_LIST = (False, True, False, False)  # âœ… åªæœ‰ row_content_list æ˜¯åˆ—è¡¨
    FUNCTION = "load_excel_batch"
    CATEGORY = "buding_Tools/èµ„äº§åŠ è½½"
    
    # âœ… ç¼“å­˜æœºåˆ¶ï¼š30 ç§’ TTL
    _scan_cache = {}

    def load_excel_batch(
        self,
        directory_path: str,
        file_type: str,
        positive_keywords: str,
        keyword_input_mode: str,
        keyword_match_mode: str,
        max_files: int,
        start_index: int,
        force_select_index: int,
        always_reload: bool,
        similarity_threshold: float,
        scan_max_depth: int,
        enable_negative_enhance: bool,
        negative_keywords: str,
        sort_mode: str,
        debug_mode: bool,
        random_selection: bool,
        seed: int,
        operation_mode: str,
        output_path: str,
        overwrite_output: bool,
        generate_merged_text: bool,
    ):
        # æ¸…ç†è·¯å¾„
        directory_path = directory_path.strip().strip('"\'')
        current_time_str = time.strftime("%Y-%m-%d %H:%M")

        # 1. æ‰«æä¸ç­›é€‰ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        all_files = self._get_cached_file_list(
            directory_path, file_type, positive_keywords, keyword_input_mode,
            keyword_match_mode, similarity_threshold, scan_max_depth,
            enable_negative_enhance, negative_keywords, sort_mode,
            debug_mode, random_selection, seed, always_reload
        )
        
        if not all_files:
            status = "ğŸ“Š âŒ åŠ è½½å¤±è´¥ï¼šæœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶"
            log = f"{status}\nç›®å½•: {directory_path}\næ—¶é—´: {current_time_str}"
            if debug_mode:
                print(f"[buding_SimpleExcelBatchLoader] {status}")
            return {"result": ("", [], "", log), "ui": {"text": status}}

        # 2. æˆªå–å½“å‰æ‰¹æ¬¡
        selected_files = all_files[start_index : start_index + max_files]
        
        if not selected_files:
            status = "ğŸ“Š âŒ åŠ è½½å¤±è´¥ï¼šç´¢å¼•è¶…å‡ºèŒƒå›´"
            log = f"{status}\nç›®å½•: {directory_path}\næ—¶é—´: {current_time_str}"
            if debug_mode:
                print(f"[buding_SimpleExcelBatchLoader] {status}")
            return {"result": ("", [], "", log), "ui": {"text": status}}

        # 3. æ‰§è¡Œæ¨¡å¼åˆ†æµ
        final_file_path = ""
        rows_for_preview = []
        
        if "Single" in operation_mode:
            # å•é€‰æ¨¡å¼
            if 0 <= force_select_index < len(selected_files):
                target_file = selected_files[force_select_index]
            else:
                target_file = selected_files[0]
            final_file_path = target_file
            rows_for_preview = self._read_any_to_rows(target_file)
        else:
            # åˆå¹¶æ¨¡å¼ (Bulk Merger)
            final_file_path = self._perform_bulk_merge(selected_files, output_path, overwrite_output, debug_mode)
            rows_for_preview = self._read_any_to_rows(final_file_path)[:20]  # ä»…è¯»å–å‰20è¡Œç”¨äºé¢„è§ˆ

        # 4. æƒ°æ€§èµ„æºä¼˜åŒ–ï¼šç”Ÿæˆå¤§æ–‡æœ¬
        merged_text_all = ""
        if generate_merged_text:
            if "Single" in operation_mode:
                # å•é€‰æ¨¡å¼ä¸‹ç”Ÿæˆæ–‡æœ¬
                merged_text_all = "\n".join([",".join(map(str, r)) for r in rows_for_preview])
            else:
                # åˆå¹¶æ¨¡å¼ä¸‹æç¤ºèŠ‚çœå†…å­˜
                merged_text_all = "åˆå¹¶ç»“æœå·²å†™å…¥ç‰©ç†æ–‡ä»¶ï¼Œæ­¤å¤„è·³è¿‡ä»¥èŠ‚çœå†…å­˜"

        # 5. ç”ŸæˆçŠ¶æ€ä¿¡æ¯ (æ–‡æœ¬è¿›åº¦æ¡)
        status_ui = self._generate_visual_status(len(selected_files), len(all_files), start_idx=start_index)
        
        # ç”ŸæˆæˆåŠŸæ—¥å¿—
        last_filename = os.path.basename(selected_files[-1]) if selected_files else "None"
        log = (
            f"ğŸ“Š æ‰¹é‡åŠ è½½å®Œæˆ | ğŸ”¢ æ€»è®¡: {len(selected_files)} ä¸ªæ–‡ä»¶\n"
            f"ğŸ“‚ æ ¹ç›®å½•: {directory_path}\n"
            f"ğŸ”š ç»“æŸäº: {last_filename}\n"
            f"ğŸ•’ æ—¶é—´: {current_time_str}"
        )

        if debug_mode:
            print(f"[buding_SimpleExcelBatchLoader] {status_ui}")
            print(f"   å·¥ä½œæ¨¡å¼: {operation_mode}")
            print(f"   è¾“å‡ºæ–‡ä»¶: {final_file_path}")
            print(f"   é¢„è§ˆè¡Œæ•°: {len(rows_for_preview)}")

        # 6. æ™ºèƒ½é˜²æ´ªä¿æŠ¤ï¼ˆéšæ€§ä¿éšœï¼‰
        self._smart_sleep(selected_files, operation_mode, debug_mode)

        return {
            "ui": {"text": status_ui},
            "result": (
                final_file_path, 
                [",".join(map(str, r)) for r in rows_for_preview], 
                merged_text_all, 
                log
            )
        }

    def _read_any_to_rows(self, file_path: str) -> list:
        """é€šç”¨è¯»å–ï¼šæ”¯æŒ .xlsx, .csv, .txt"""
        rows = []
        ext = os.path.splitext(file_path)[1].lower()
        try:
            if ext == ".xlsx":
                if 'openpyxl' in globals():
                    wb = openpyxl.load_workbook(file_path, data_only=True)
                    ws = wb.active
                    for row in ws.iter_rows(values_only=True):
                        rows.append(list(row) if row else [])
                    wb.close()
                else:
                    print(f"[buding_Tools] è­¦å‘Š: éœ€è¦å®‰è£… openpyxl æ¥è¯»å– .xlsx æ–‡ä»¶: {file_path}")
            elif ext == ".csv":
                with open(file_path, "r", encoding="utf-8-sig") as f:
                    rows = list(csv.reader(f))
            elif ext == ".txt":
                # TXTå®¹å™¨åŒ–é€»è¾‘
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    rows = [["Filename", "Content"], [os.path.basename(file_path), content]]
        except Exception as e:
            print(f"[buding_Tools] è¯»å–å¤±è´¥: {file_path}, {e}")
        return rows

    def _perform_bulk_merge(self, files: list, output_path: str, overwrite_output: bool, debug_mode: bool = False) -> str:
        """æ‰§è¡Œç‰©ç†åˆå¹¶é€»è¾‘ï¼šWPS å…¼å®¹æ€§ä¼˜åŒ–"""
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        user_path = output_path.strip()
        if user_path:
            out_file = user_path if user_path.lower().endswith(".csv") else user_path + ".csv"
            # è‡ªåŠ¨å»ºè·¯é€»è¾‘
            out_dir = os.path.dirname(out_file)
            if out_dir and not os.path.exists(out_dir):
                os.makedirs(out_dir, exist_ok=True)
                if debug_mode:
                    print(f"   è‡ªåŠ¨åˆ›å»ºç›®å½•: {out_dir}")
        else:
            timestamp = int(time.time())
            out_file = os.path.join(self.comfy_output_dir, f"buding_merged_assets_{timestamp}.csv")

        # è¦†ç›–é€»è¾‘
        if not overwrite_output and os.path.exists(out_file):
            out_file = out_file.replace(".csv", f"_{int(time.time())}.csv")
            if debug_mode:
                print(f"   æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶: {out_file}")

        # ç‰©ç†åˆå¹¶å†™å…¥
        try:
            with open(out_file, "w", newline="", encoding="utf-8-sig") as f:  # utf-8-sig (BOM) è§£å†³ WPS ä¹±ç 
                writer = csv.writer(f)
                main_header = None
                
                for i, f_path in enumerate(files):
                    current_rows = self._read_any_to_rows(f_path)
                    if not current_rows: 
                        continue
                    
                    if debug_mode:
                        print(f"   åˆå¹¶æ–‡ä»¶ {i+1}/{len(files)}: {os.path.basename(f_path)} ({len(current_rows)} è¡Œ)")
                    
                    if i == 0:
                        # ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼šå†™å…¥å…¨éƒ¨ï¼ˆåŒ…æ‹¬è¡¨å¤´ï¼‰
                        main_header = current_rows[0] if current_rows else []
                        writer.writerows(current_rows)
                    else:
                        # åç»­æ–‡ä»¶ï¼šè¡¨å¤´å¹³æƒé€»è¾‘ï¼Œè·³è¿‡è¡¨å¤´åªå†™æ•°æ®
                        if len(current_rows) > 1:
                            # ç¡®ä¿åˆ—æ•°ä¸ä¸»è¡¨å¤´ä¸€è‡´
                            data_rows = current_rows[1:]
                            if main_header:
                                # å¡«å……åˆ—æ•°ä¸è¶³çš„è¡Œ
                                for row in data_rows:
                                    while len(row) < len(main_header):
                                        row.append("")
                                writer.writerows(data_rows)
                            else:
                                writer.writerows(data_rows)
                        
            if debug_mode:
                print(f"   åˆå¹¶å®Œæˆ: {out_file}")
                
        except Exception as e:
            print(f"[buding_Tools] åˆå¹¶å¤±è´¥: {e}")
            return ""
                    
        return out_file

    def _generate_visual_status(self, current_batch: int, total: int, start_idx: int = 0) -> str:
        """ç”Ÿæˆå¯è§†åŒ–çŠ¶æ€ä¿¡æ¯"""
        if total == 0: 
            return "âš ï¸ æ— æ–‡ä»¶"
        
        progress = min(1.0, (start_idx + current_batch) / total)
        bar_len = 10
        filled = int(bar_len * progress)
        bar = "â– " * filled + "â–¡" * (bar_len - filled)
        
        batch_num = start_idx // current_batch + 1 if current_batch > 0 else 1
        return f"ğŸš€ ç¬¬ {batch_num} æ‰¹ | [{bar}] {int(progress*100)}% | èŒƒå›´: {start_idx}-{start_idx+current_batch-1} | æ€»æ•°: {total}"

    def _get_cached_file_list(self, directory_path: str, file_type: str, positive_keywords: str,
                              keyword_input_mode: str, keyword_match_mode: str, 
                              similarity_threshold: float, scan_max_depth: int,
                              enable_negative_enhance: bool, negative_keywords: str,
                              sort_mode: str, debug_mode: bool, random_selection: bool, 
                              seed: int, always_reload: bool = False) -> list:
        """âœ… ç¼“å­˜åŒ…è£…ï¼š30 ç§’ TTL"""
        # ç¼“å­˜é”®ï¼šåŸºäºæ‰«æç›¸å…³å‚æ•°
        cache_key = (
            directory_path, file_type, scan_max_depth,
            positive_keywords, keyword_input_mode, keyword_match_mode,
            enable_negative_enhance, negative_keywords,
            sort_mode, random_selection, seed
        )
        
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._scan_cache and not always_reload:
            cached_time, cached_files = self._scan_cache[cache_key]
            if current_time - cached_time < 30:  # 30 ç§’ TTL
                if debug_mode:
                    print(f"[buding_SimpleExcelBatchLoader] âœ… ä½¿ç”¨ç¼“å­˜ç»“æœ")
                return cached_files
        
        # æ‰§è¡Œæ‰«æ
        result = self._scan_excel_files(
            directory_path, file_type, positive_keywords, keyword_input_mode,
            keyword_match_mode, similarity_threshold, scan_max_depth,
            enable_negative_enhance, negative_keywords, sort_mode,
            debug_mode, random_selection, seed
        )
        
        # ç¼“å­˜ç»“æœ
        self._scan_cache[cache_key] = (current_time, result)
        return result

    def _scan_excel_files(
        self, 
        directory_path: str, 
        file_type: str, 
        positive_keywords: str, 
        keyword_input_mode: str,
        keyword_match_mode: str, 
        similarity_threshold: float, 
        scan_max_depth: int,
        enable_negative_enhance: bool, 
        negative_keywords: str, 
        sort_mode: str,
        debug_mode: bool, 
        random_selection: bool, 
        seed: int
    ) -> list:
        """æ‰«æè¡¨æ ¼æ–‡ä»¶"""
        if not directory_path or not os.path.exists(directory_path):
            if debug_mode:
                print(f"[buding_SimpleExcelBatchLoader] ç›®å½•ä¸å­˜åœ¨: {directory_path}")
            return []
        
        # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        type_extensions = {
            ".xlsx": [".xlsx"],
            ".csv": [".csv"], 
            ".txt": [".txt"],
            "all": [".xlsx", ".csv", ".txt"]
        }
        
        extensions = type_extensions.get(file_type, type_extensions["all"])
        
        # æ‰«ææ–‡ä»¶
        all_files = []
        directory = Path(directory_path)
        
        for ext in extensions:
            pattern = f"*{ext}"
            if scan_max_depth == 1:
                files = list(directory.glob(pattern))
            else:
                files = list(directory.rglob(pattern))
                # é™åˆ¶æ·±åº¦
                if scan_max_depth > 1:
                    files = [f for f in files if len(f.relative_to(directory).parts) <= scan_max_depth]
            
            all_files.extend(files)
        
        # è½¬æ¢ä¸ºæ–‡ä»¶ä¿¡æ¯å­—å…¸
        file_infos = []
        for file_path in all_files:
            if file_path.is_file():
                stat = file_path.stat()
                file_infos.append({
                    'path': str(file_path),
                    'name': file_path.name,
                    'size': stat.st_size,
                    'mtime': stat.st_mtime
                })
        
        if debug_mode:
            print(f"[buding_SimpleExcelBatchLoader] æ‰«æå®Œæˆ: æ‰¾åˆ° {len(file_infos)} ä¸ªæ–‡ä»¶")
        
        # åº”ç”¨å…³é”®è¯è¿‡æ»¤
        if positive_keywords:
            file_infos = self._apply_positive_filter(file_infos, positive_keywords, keyword_input_mode, keyword_match_mode, debug_mode)
        
        if enable_negative_enhance and negative_keywords:
            file_infos = self._apply_negative_filter(file_infos, negative_keywords, debug_mode)
        
        # æ’åº
        file_infos = self._sort_files(file_infos, sort_mode, debug_mode)
        
        # éšæœºé€‰æ‹©
        if random_selection:
            if seed == 0:
                seed = random.randint(0, 0xFFFFFFFFFFFFFFFF)
            random.seed(seed)
            random.shuffle(file_infos)
            if debug_mode:
                print(f"[buding_SimpleExcelBatchLoader] éšæœºæ’åºå®Œæˆï¼Œç§å­: {seed}")
        
        # è¿”å›æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        return [info['path'] for info in file_infos]

    def _apply_positive_filter(self, file_infos: list, keywords: str, input_mode: str, match_mode: str, debug_mode: bool = False) -> list:
        """åº”ç”¨æ­£å‘å…³é”®è¯ç­›é€‰"""
        if not keywords.strip():
            return file_infos
        
        # è§£æå…³é”®è¯
        if input_mode == "å¤šè¡Œæ–‡æœ¬":
            keyword_list = [kw.strip() for kw in keywords.split('\n') if kw.strip()]
        else:
            keyword_list = [kw.strip() for kw in keywords.replace('ã€', ' ').split() if kw.strip()]
        
        filtered = []
        for file_info in file_infos:
            file_name = file_info['name'].lower()
            
            for keyword in keyword_list:
                keyword_lower = keyword.lower()
                
                if match_mode == "ç²¾ç¡®åŒ¹é…":
                    if keyword_lower == file_name:
                        filtered.append(file_info)
                        break
                elif match_mode == "æ­£åˆ™è¡¨è¾¾å¼":
                    try:
                        if re.search(keyword, file_name, re.IGNORECASE):
                            filtered.append(file_info)
                            break
                    except re.error:
                        pass
                else:  # åŒ…å«åŒ¹é…
                    if keyword_lower in file_name:
                        filtered.append(file_info)
                        break
        
        if debug_mode:
            print(f"[buding_SimpleExcelBatchLoader] æ­£å‘ç­›é€‰: {len(file_infos)} -> {len(filtered)} ä¸ªæ–‡ä»¶")
        
        return filtered

    def _apply_negative_filter(self, file_infos: list, keywords: str, debug_mode: bool = False) -> list:
        """åº”ç”¨åå‘å…³é”®è¯ç­›é€‰"""
        if not keywords.strip():
            return file_infos
        
        keyword_list = [kw.strip() for kw in keywords.split('\n') if kw.strip()]
        
        filtered = []
        for file_info in file_infos:
            file_name = file_info['name'].lower()
            should_exclude = False
            
            for keyword in keyword_list:
                if keyword.lower() in file_name:
                    should_exclude = True
                    break
            
            if not should_exclude:
                filtered.append(file_info)
        
        if debug_mode:
            print(f"[buding_SimpleExcelBatchLoader] åå‘ç­›é€‰: {len(file_infos)} -> {len(filtered)} ä¸ªæ–‡ä»¶")
        
        return filtered

    def _sort_files(self, file_infos: list, sort_mode: str, debug_mode: bool = False) -> list:
        """æ–‡ä»¶æ’åº"""
        if sort_mode == "name":
            sorted_files = sorted(file_infos, key=lambda x: x['name'].lower())
        elif sort_mode == "date_newest":
            sorted_files = sorted(file_infos, key=lambda x: x['mtime'], reverse=True)
        elif sort_mode == "date_oldest":
            sorted_files = sorted(file_infos, key=lambda x: x['mtime'])
        elif sort_mode == "size":
            sorted_files = sorted(file_infos, key=lambda x: x['size'], reverse=True)
        else:
            sorted_files = file_infos
        
        if debug_mode:
            print(f"[buding_SimpleExcelBatchLoader] æ’åºå®Œæˆ: æ¨¡å¼={sort_mode}")
        
        return sorted_files

    def _smart_sleep(self, selected_files, operation_mode, debug_mode):
        """æ™ºèƒ½é˜²æ´ªå»¶è¿Ÿï¼šæ ¹æ®ä»»åŠ¡å¼ºåº¦åŠ¨æ€è°ƒæ•´"""
        delay = 0.0
        
        # åŸºç¡€åˆ¤å®šï¼šåˆå¹¶æ¨¡å¼æˆ–å¤§é‡æ–‡ä»¶å¤„ç†
        if "Bulk" in operation_mode:
            delay = 0.05  # åˆå¹¶æ¨¡å¼åŸºç¡€ç¼“å†²
        
        if len(selected_files) > 50:
            delay += 0.05
        if len(selected_files) > 100:
            delay += 0.05

        if delay > 0:
            if debug_mode:
                print(f"[buding_Tools] ğŸ›¡ï¸ æ™ºèƒ½é˜²æ´ªï¼šå»¶è¿Ÿ {int(delay*1000)}ms ä¿æŠ¤ç³»ç»Ÿ...")
            time.sleep(delay)  # âœ… ç›´æ¥ä½¿ç”¨é¡¶éƒ¨å¯¼å…¥çš„ time

    @classmethod
    def IS_CHANGED(cls, directory_path, file_type, positive_keywords, keyword_input_mode,
                   keyword_match_mode, max_files, start_index, force_select_index,
                   always_reload, similarity_threshold, scan_max_depth,
                   enable_negative_enhance, negative_keywords, sort_mode,
                   debug_mode, random_selection, seed, operation_mode,
                   output_path, overwrite_output, generate_merged_text):
        """åŸºäºå…³é”®å‚æ•°çš„ç¨³å®šå“ˆå¸Œï¼Œé˜²æ­¢æ— é™å¾ªç¯é‡æ¸²æŸ“"""
        if always_reload:
            return float("nan")  # å¼ºåˆ¶é‡æ–°åŠ è½½
        
        # âœ… åŒ…å«æ‰€æœ‰ 20 ä¸ªå‚æ•°ï¼Œç¡®ä¿å‚æ•°æ”¹å˜æ—¶åˆ·æ–°
        key_params = {
            'directory_path': directory_path,
            'file_type': file_type,
            'positive_keywords': positive_keywords,
            'keyword_input_mode': keyword_input_mode,
            'keyword_match_mode': keyword_match_mode,
            'max_files': max_files,
            'start_index': start_index,
            'force_select_index': force_select_index,
            'similarity_threshold': similarity_threshold,
            'scan_max_depth': scan_max_depth,
            'enable_negative_enhance': enable_negative_enhance,
            'negative_keywords': negative_keywords,
            'sort_mode': sort_mode,  # â† å…³é”®
            'debug_mode': debug_mode,
            'random_selection': random_selection,
            'seed': seed,
            'operation_mode': operation_mode,
            'output_path': output_path,
            'overwrite_output': overwrite_output,
            'generate_merged_text': generate_merged_text,
        }
        return hash(frozenset(key_params.items()))  # âœ… æ”¹ç”¨ frozenset æé«˜æ€§èƒ½

# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "buding_SimpleExcelBatchLoader": buding_SimpleExcelBatchLoader,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "buding_SimpleExcelBatchLoader": "ğŸ“Š buding_SimpleExcelBatchLoader (ç®€åŒ–Excelæ‰¹é‡åŠ è½½å™¨)",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']
