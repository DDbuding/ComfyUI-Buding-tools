import os
import re
import shutil
import subprocess
import tempfile
from typing import List, Optional, Sequence, Tuple

import torch
import torchaudio
from torchaudio.transforms import Resample

import comfy.utils


class AudioStitcherABC:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "sources_A": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "A(ç‰‡å¤´): ç•™ç©ºåˆ™è·³è¿‡ï¼Œæ”¯æŒè¾“å…¥å•ä¸ªæ–‡ä»¶æˆ–ç›®å½•ï¼Œå¤šè¡Œå¯æ··è¾“",
                    "tooltip": "ç‰‡å¤´éŸ³é¢‘æºï¼šæ”¯æŒç›´æ¥å¡«æ–‡ä»¶å®Œæ•´è·¯å¾„ï¼Œæˆ–å¡«ç›®å½•è‡ªåŠ¨æ‰¹é‡è¯»å–ï¼›å¯å¤šè¡Œè¾“å…¥å¤šä¸ªè·¯å¾„/ç›®å½•ï¼Œè‡ªåŠ¨æ•°å­—é¡ºåºæ’åºã€‚"
                }),
                "sources_B": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "B(æ­£æ–‡): å¿…å¡«ï¼Œæ”¯æŒæ–‡ä»¶æˆ–ç›®å½•ï¼Œå¤šè¡Œå¯æ··è¾“",
                    "tooltip": "æ­£æ–‡éŸ³é¢‘æºï¼šå¿…é¡»æä¾›ã€‚æ”¯æŒå¡«å•ä¸ªæ–‡ä»¶æˆ–ç›®å½•ï¼ˆè‡ªåŠ¨æ‰«ææ”¯æŒçš„éŸ³é¢‘åç¼€ï¼‰ï¼Œå¯å¤šè¡Œæ··åˆè¾“å…¥ï¼›ä¼šæŒ‰æ–‡ä»¶åæ•°å­—ä¼˜å…ˆæ’åºã€‚"
                }),
                "sources_C": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "C(ç‰‡å°¾): ç•™ç©ºåˆ™è·³è¿‡ï¼Œæ”¯æŒæ–‡ä»¶/ç›®å½•ï¼Œå¤šè¡Œå¯æ··è¾“",
                    "tooltip": "ç‰‡å°¾éŸ³é¢‘æºï¼šå¯é€‰ã€‚æ”¯æŒæ–‡ä»¶æˆ–ç›®å½•ï¼Œå¤šè¡Œæ··åˆè¾“å…¥ï¼›æœªæä¾›åˆ™è·³è¿‡ç‰‡å°¾æ‹¼æ¥ã€‚"
                }),
                "mode": ([
                    "æ‰¹é‡_å¾ªç¯è¡¥é½ (Loop)",
                    "æ‰¹é‡_ç´¢å¼•å¯¹é½ (Index)",
                    "æ‰¹é‡_1å¯¹N (A1+C1+æ‰€æœ‰B)",
                    "å•æ¡_ä»…é¦–ä¸ª (Single)",
                ], {"default": "æ‰¹é‡_ç´¢å¼•å¯¹é½ (Index)", "tooltip": "æ‰¹é‡ï¼šæŒ‰æ¨¡å¼å¾ªç¯/å¯¹é½ï¼›å•æ¡ï¼šåªå–å„åˆ—è¡¨ç¬¬1ä¸ªæ–‡ä»¶å¿«é€Ÿé¢„è§ˆ"}),
                "limit_count": ("INT", {"default": 0, "min": 0, "max": 9999, "tooltip": "æ‰¹é‡æ¨¡å¼æ•°é‡ä¸Šé™ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶ï¼›å•æ¡æ¨¡å¼æ— è§†è¯¥é™åˆ¶"}),
                "norm_A_dB": ("FLOAT", {"default": -3.0, "step": 0.5, "tooltip": "ç‰‡å¤´éŸ³é‡å½’ä¸€åŒ–ç›®æ ‡ (dB)ï¼Œå•ç‹¬ä½œç”¨äºA"}),
                "norm_B_dB": ("FLOAT", {"default": -3.0, "step": 0.5, "tooltip": "æ­£æ–‡éŸ³é‡å½’ä¸€åŒ–ç›®æ ‡ (dB)ï¼Œä½œç”¨äºB"}),
                "norm_C_dB": ("FLOAT", {"default": -3.0, "step": 0.5, "tooltip": "ç‰‡å°¾éŸ³é‡å½’ä¸€åŒ–ç›®æ ‡ (dB)ï¼Œä½œç”¨äºC"}),
                "offset_A_B": ("FLOAT", {"default": -0.5, "step": 0.1, "label": "A-B è¿æ¥(è´Ÿæ•°é‡å )", "tooltip": "A ä¸ B çš„æ—¶é—´åç§»ï¼šè´Ÿæ•°è¡¨ç¤ºé‡å æ··éŸ³ï¼Œæ­£æ•°è¡¨ç¤ºæ’å…¥é™éŸ³é—´éš”"}),
                "offset_B_C": ("FLOAT", {"default": 1.0, "step": 0.1, "label": "B-C è¿æ¥(æ­£æ•°é—´éš”)", "tooltip": "B ä¸ C çš„æ—¶é—´åç§»ï¼šè´Ÿæ•°é‡å ï¼Œæ­£æ•°ç•™é—´éš”"}),
                "trim_silence": ("BOOLEAN", {"default": True, "tooltip": "è£å‰ªå„ç‰‡æ®µé¦–å°¾é™éŸ³ï¼ˆ-45dB é˜ˆå€¼ï¼Œ10ms ä½™é‡ï¼‰"}),
                "edge_fade": ("INT", {"default": 10, "min": 0, "max": 2000, "tooltip": "æ•´æ®µé¦–å°¾æ·¡å…¥/æ·¡å‡ºæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ã€‚0 å…³é—­æ·¡å˜ã€‚"}),
                "save_file": ("BOOLEAN", {"default": True, "tooltip": "ä¿å­˜æ‹¼æ¥ç»“æœåˆ°ç£ç›˜"}),
                "save_path": ("STRING", {"default": "", "placeholder": "C:/Output/Audio", "tooltip": "å¯¼å‡ºç›®å½•ï¼Œç•™ç©ºåˆ™ä¸ä¿å­˜"}),
                "naming_mode": (["å‰ç¼€+åºå·", "Båç§°+æ‰©å±•åç¼€"], {"default": "å‰ç¼€+åºå·", "tooltip": "é€‰æ‹©å¯¼å‡ºå‘½åæ–¹å¼ï¼š\n- å‰ç¼€+åºå·ï¼šä½¿ç”¨å‰ç¼€+å››ä½ç¼–å·\n- Båç§°+æ‰©å±•åç¼€ï¼šä½¿ç”¨Bæ–‡ä»¶åï¼ˆæˆ–ç›®å½•åï¼‰+å¯é€‰åç¼€"}),
                "file_prefix": ("STRING", {"default": "Ep_", "tooltip": "å‘½åæ–¹å¼ä¸ºå‰ç¼€+åºå·æ—¶çš„å‰ç¼€ï¼Œä¾‹å¦‚ Ep_0001.wav"}),
                "name_suffix": ("STRING", {"default": "", "tooltip": "å‘½åæ–¹å¼ä¸ºBåç§°+æ‰©å±•åç¼€æ—¶ä½¿ç”¨ï¼Œä¾‹å¦‚ B=å¥³å£°1ï¼Œåç¼€=Sï¼Œç»“æœä¸º S-å¥³å£°1.wavï¼›åç¼€ç•™ç©ºåˆ™ç›´æ¥ç”¨Båã€‚"}),
                "ffmpeg_fallback": ("BOOLEAN", {"default": True, "tooltip": "å½“ torchaudio è¯»å–å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨è°ƒç”¨ ffmpeg è§£ç ä¸º WAV å†æ‹¼æ¥ï¼ˆéœ€ç³»ç»Ÿå·²å®‰è£… ffmpegï¼‰ã€‚å…³é—­å¯ç•¥å¾®æå‡æ€§èƒ½ã€‚"}),
                "debug_mode": ("BOOLEAN", {"default": False, "tooltip": "å¼€å¯åè¾“å‡ºè¯¦ç»†è°ƒè¯•æ—¥å¿—ï¼Œä¾¿äºæ’æŸ¥åŠ è½½/æ‹¼æ¥é—®é¢˜"}),
            }
        }

    RETURN_TYPES = ("AUDIO", "STRING")
    RETURN_NAMES = ("audio_batch", "log_info")
    FUNCTION = "stitch"
    CATEGORY = "buding_Tools/éŸ³é¢‘å¤„ç†"

    @staticmethod
    def _natural_key(name: str) -> List[object]:
        return [int(t) if t.isdigit() else t.lower() for t in re.split(r"([0-9]+)", name)]

    @classmethod
    def _gather_files(cls, raw: Sequence[str]) -> List[Tuple[str, str]]:
        if raw is None:
            return []
        valid_ext = (".wav", ".mp3", ".flac", ".m4a", ".ogg")
        file_list: List[Tuple[str, str]] = []
        paths: List[str] = []

        def clean_path(p: str) -> str:
            return str(p).strip().strip('"').strip("'")

        if isinstance(raw, str):
            paths = [clean_path(p) for p in raw.split("\n") if p.strip()]
        else:
            paths = [clean_path(p) for p in raw if str(p).strip()]

        for path in paths:
            if os.path.isfile(path) and path.lower().endswith(valid_ext):
                file_list.append((path, path))
            elif os.path.isdir(path):
                for fname in os.listdir(path):
                    if fname.lower().endswith(valid_ext):
                        file_list.append((os.path.join(path, fname), path))

        file_list.sort(key=lambda x: cls._natural_key(os.path.basename(x[0])))
        return file_list

    @staticmethod
    def _trim_silence_if_needed(wav: Optional[torch.Tensor], sr: int, enable: bool) -> Optional[torch.Tensor]:
        if wav is None or not enable:
            return wav
        mono = wav.abs().max(dim=0).values
        threshold = 10 ** (-45.0 / 20)
        mask = (mono > threshold).nonzero(as_tuple=False).flatten()
        if mask.numel() == 0:
            return wav
        start = mask[0].item()
        end = mask[-1].item() + 1
        margin = int(0.01 * sr)
        start = max(0, start - margin)
        end = min(mono.numel(), end + margin)
        if end - start <= 0:
            return wav
        return wav[:, start:end]

    @staticmethod
    def _decode_with_ffmpeg(path: str, target_sr: int) -> Tuple[Optional[torch.Tensor], Optional[str]]:
        ffmpeg_bin = shutil.which("ffmpeg")
        if not ffmpeg_bin:
            return None, "æœªæ‰¾åˆ° ffmpeg å¯æ‰§è¡Œæ–‡ä»¶"
        tmp_path = None
        try:
            tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            tmp_path = tmp_file.name
            tmp_file.close()

            cmd = [
                ffmpeg_bin,
                "-y",
                "-loglevel",
                "error",
                "-i",
                path,
                "-ar",
                str(target_sr),
                "-ac",
                "2",
                "-f",
                "wav",
                tmp_path,
            ]
            proc = subprocess.run(cmd, capture_output=True)
            if proc.returncode != 0:
                stderr = proc.stderr.decode("utf-8", errors="ignore") if proc.stderr else ""
                return None, f"ffmpeg è§£ç å¤±è´¥: {stderr.strip()}"

            wav, sr = torchaudio.load(tmp_path)
            wav = wav.float()
            if sr != target_sr:
                wav = Resample(sr, target_sr)(wav)
            if wav.shape[0] == 1:
                wav = wav.repeat(2, 1)
            elif wav.shape[0] > 2:
                wav = wav[:2, :]
            return wav, None
        except Exception as exc:  # noqa: BLE001
            return None, f"ffmpeg è§£ç å¼‚å¸¸: {exc}"
        finally:
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.remove(tmp_path)
                except OSError:
                    pass

    @staticmethod
    def _load_clip(path: Optional[str], target_db: float, target_sr: int, trim_silence: bool, ffmpeg_fallback: bool) -> Tuple[Optional[torch.Tensor], Optional[str]]:
        if not path:
            return None, "æœªæä¾›è·¯å¾„"
        try:
            wav, sr = torchaudio.load(path)
            wav = wav.float()
            if sr != target_sr:
                wav = Resample(sr, target_sr)(wav)
            if wav.shape[0] == 1:
                wav = wav.repeat(2, 1)
            elif wav.shape[0] > 2:
                wav = wav[:2, :]
            max_val = torch.max(torch.abs(wav)).item()
            if max_val > 0:
                target_amp = 10 ** (target_db / 20)
                wav = wav * (target_amp / max_val)
            wav = AudioStitcherABC._trim_silence_if_needed(wav, target_sr, trim_silence)
            return wav, None
        except Exception as exc:  # noqa: BLE001
            if not ffmpeg_fallback:
                return None, f"åŠ è½½å¤±è´¥: {exc}"
            ffmpeg_wav, ffmpeg_err = AudioStitcherABC._decode_with_ffmpeg(path, target_sr)
            if ffmpeg_wav is None:
                return None, ffmpeg_err
            max_val = torch.max(torch.abs(ffmpeg_wav)).item()
            if max_val > 0:
                target_amp = 10 ** (target_db / 20)
                ffmpeg_wav = ffmpeg_wav * (target_amp / max_val)
            ffmpeg_wav = AudioStitcherABC._trim_silence_if_needed(ffmpeg_wav, target_sr, trim_silence)
            return ffmpeg_wav, None

    @staticmethod
    def _stitch_two(w1: Optional[torch.Tensor], w2: Optional[torch.Tensor], offset: float, sr: int) -> Optional[torch.Tensor]:
        if w1 is None:
            return w2
        if w2 is None:
            return w1
        offset_frames = int(abs(offset) * sr)
        len1, len2 = w1.shape[1], w2.shape[1]
        if offset < 0:  # overlap mix
            overlap = min(offset_frames, min(len1, len2))
            total = max(len1, len2 + len1 - overlap)
            out = torch.zeros((2, total), device=w1.device, dtype=w1.dtype)
            out[:, :len1] = w1
            start2 = max(0, len1 - overlap)
            valid2 = min(len2, total - start2)
            out[:, start2:start2 + valid2] += w2[:, :valid2]
            return out
        gap = torch.zeros((2, offset_frames), device=w1.device, dtype=w1.dtype)
        return torch.cat((w1, gap, w2), dim=1)

    def stitch(
        self,
        sources_A: Sequence[str],
        sources_B: Sequence[str],
        sources_C: Sequence[str],
        norm_A_dB: float,
        norm_B_dB: float,
        norm_C_dB: float,
        mode: str,
        offset_A_B: float,
        offset_B_C: float,
        trim_silence: bool,
        edge_fade: int,
        limit_count: int,
        save_file: bool,
        save_path: str,
        naming_mode: str,
        file_prefix: str,
        name_suffix: str,
        ffmpeg_fallback: bool,
        debug_mode: bool,
    ) -> Tuple[Optional[dict], str]:
        list_A = self._gather_files(sources_A)
        list_B = self._gather_files(sources_B)
        list_C = self._gather_files(sources_C)

        if not list_B:
            return None, "âŒ é”™è¯¯ï¼šB æºä¸ºç©ºï¼Œæ— æ³•æ‹¼æ¥"

        target_sr = 44100
        mode_single = "å•æ¡" in mode or "Single" in mode
        mode_index = "ç´¢å¼•" in mode
        mode_one_to_many = "1å¯¹N" in mode

        max_iter = len(list_B)
        if mode_single:
            max_iter = 1
        elif mode_index:
            valid_lengths = [l for l in [len(list_A), len(list_B), len(list_C)] if l > 0]
            max_iter = min(valid_lengths) if valid_lengths else 0
        elif mode_one_to_many:
            max_iter = len(list_B)

        if limit_count > 0 and not mode_single:
            max_iter = min(max_iter, limit_count)

        triplets = []
        for i in range(max_iter):
            idx_A = 0 if (mode_one_to_many or mode_single) else (i % len(list_A) if list_A else None)
            idx_B = 0 if mode_single else (i % len(list_B))
            idx_C = 0 if (mode_one_to_many or mode_single) else (i % len(list_C) if list_C else None)

            fA_path = list_A[idx_A][0] if idx_A is not None and list_A else None
            fB_path, fB_root = list_B[idx_B]
            fC_path = list_C[idx_C][0] if idx_C is not None and list_C else None
            triplets.append((fA_path, fB_path, fC_path, fB_root))

        if not triplets:
            return None, "âš ï¸ æ²¡æœ‰å¯å¤„ç†çš„ä»»åŠ¡ï¼Œæ£€æŸ¥è¾“å…¥åˆ—è¡¨"

        if save_file and save_path:
            os.makedirs(save_path, exist_ok=True)

        output_tensors: List[torch.Tensor] = []
        success = 0
        failures: List[str] = []
        pbar = comfy.utils.ProgressBar(len(triplets))

        for idx, (pA, pB, pC, rootB) in enumerate(triplets):
            try:
                wav_A, err_A = self._load_clip(pA, norm_A_dB, target_sr, trim_silence, ffmpeg_fallback)
                wav_B, err_B = self._load_clip(pB, norm_B_dB, target_sr, trim_silence, ffmpeg_fallback)
                wav_C, err_C = self._load_clip(pC, norm_C_dB, target_sr, trim_silence, ffmpeg_fallback)

                if debug_mode:
                    print(f"[AudioStitcher] Task {idx+1}: A={pA}, B={pB}, C={pC}, rootB={rootB}")
                    if wav_A is None:
                        print(f"[AudioStitcher] A åŠ è½½å¤±è´¥æˆ–æœªæä¾›: {err_A}")
                    if wav_B is None:
                        print(f"[AudioStitcher] B åŠ è½½å¤±è´¥æˆ–æœªæä¾›: {err_B}")
                    if wav_C is None and pC:
                        print(f"[AudioStitcher] C åŠ è½½å¤±è´¥: {err_C}")

                if pA and wav_A is None:
                    raise RuntimeError(f"A ç‰‡æ®µåŠ è½½å¤±è´¥: {pA} ({err_A})")
                if wav_B is None:
                    raise RuntimeError(f"B ç‰‡æ®µåŠ è½½å¤±è´¥ï¼Œæ— æ³•æ‹¼æ¥: {pB} ({err_B})")
                if pC and wav_C is None:
                    raise RuntimeError(f"C ç‰‡æ®µåŠ è½½å¤±è´¥: {pC} ({err_C})")

                current = self._stitch_two(wav_A, wav_B, offset_A_B, target_sr)
                final = self._stitch_two(current, wav_C, offset_B_C, target_sr)

                if final is None:
                    raise RuntimeError("æ‹¼æ¥ç»“æœä¸ºç©º")

                if edge_fade > 0:
                    fade_len = int((edge_fade / 1000) * target_sr)
                    if fade_len * 2 < final.shape[1] and fade_len > 0:
                        fade_in = torch.linspace(0, 1, fade_len, device=final.device).unsqueeze(0).repeat(2, 1)
                        fade_out = torch.linspace(1, 0, fade_len, device=final.device).unsqueeze(0).repeat(2, 1)
                        final[:, :fade_len] *= fade_in
                        final[:, -fade_len:] *= fade_out

                output_tensors.append(final.unsqueeze(0))
                if save_file and save_path:
                    suffix = name_suffix.strip()
                    if naming_mode == "Båç§°+æ‰©å±•åç¼€":
                        base_name_file = os.path.splitext(os.path.basename(pB or ""))[0]
                        base_name_dir = os.path.basename(rootB or "") if rootB else ""
                        # å¦‚æœæ ¹è·¯å¾„æ˜¯ç›®å½•ï¼Œåˆ™ä¼˜å…ˆç”¨ç›®å½•åï¼›å¦åˆ™ç”¨æ–‡ä»¶å
                        base_name = base_name_dir if rootB and os.path.isdir(rootB) else base_name_file
                        base_name = base_name or "output"
                        if suffix:
                            fname_core = f"{suffix}-{base_name}-{idx + 1:04d}"
                        else:
                            fname_core = f"{base_name}-{idx + 1:04d}"
                    else:
                        fname_core = f"{file_prefix}{idx + 1:04d}"
                    fname = f"{fname_core}.wav"
                    torchaudio.save(os.path.join(save_path, fname), final.cpu(), target_sr)
                success += 1
            except Exception as exc:  # noqa: BLE001
                failures.append(f"Task {idx + 1}: {exc}")
            finally:
                pbar.update(1)

        if success == 0:
            error_msg = failures[0] if failures else "ç”Ÿæˆå¤±è´¥ï¼Œæœªå¾—åˆ°æœ‰æ•ˆéŸ³é¢‘"
            raise RuntimeError(error_msg)

        if output_tensors:
            max_len = max(t.shape[2] for t in output_tensors)
            padded = []
            for t in output_tensors:
                if t.shape[2] < max_len:
                    pad_len = max_len - t.shape[2]
                    pad = torch.zeros((1, t.shape[1], pad_len), device=t.device, dtype=t.dtype)
                    t = torch.cat((t, pad), dim=2)
                padded.append(t)
            waveform = torch.cat(padded, dim=0)
            audio_batch = {"waveform": waveform, "sample_rate": target_sr}
        else:
            audio_batch = None

        fail_msg = f"\nâŒ å¤±è´¥: {len(failures)}" if failures else ""
        if failures:
            for msg in failures:
                print(msg)
        mode_str = "ğŸŸ¢ å•æ¡æ¨¡å¼" if mode_single else f"ğŸŸ  æ‰¹é‡æ¨¡å¼ ({mode})"
        save_state = save_path if (save_file and save_path) else "æœªå¼€å¯ä¿å­˜"

        log_text = (
            f"âœ… å¤„ç†å®Œæˆ\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"âš™ï¸ æ¨¡å¼: {mode_str}\n"
            f"ğŸ“¥ é˜Ÿåˆ—: {len(triplets)} ä¸ªä»»åŠ¡\n"
            f"ğŸ“Š æˆåŠŸ: {success} ä¸ª\n"
            f"ğŸ’¾ è·¯å¾„: {save_state}"
            f"{fail_msg}"
        )
        print(log_text)

        return audio_batch, log_text


NODE_CLASS_MAPPINGS = {
    "AudioStitcherABC": AudioStitcherABC,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AudioStitcherABC": "ğŸµ Audio Stitcher (A-B-C)",
}
