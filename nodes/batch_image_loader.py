"""
buding_BatchImageLoader - æ™ºèƒ½å›¾åƒæ‰¹é‡åŠ è½½å™¨
ä¸“ä¸ºAIå›¾åƒèµ„äº§ç®¡ç†è®¾è®¡ï¼Œæ”¯æŒå¤§è§„æ¨¡å›¾åƒå¤„ç†çš„æ€§èƒ½ä¼˜åŒ–å’Œæ™ºèƒ½ç­›é€‰

æ ¸å¿ƒåŠŸèƒ½ï¼š
- ä¸¤éæ‰«æå†…å­˜ä¼˜åŒ–æœºåˆ¶
- OpenCV/PillowåŒåç«¯æ”¯æŒ
- PNGå…ƒæ•°æ®æ™ºèƒ½ç­›é€‰
- åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”ç²¾ç¡®åŒ¹é…
- æ™ºèƒ½æ˜ å°„ç³»ç»Ÿ
- åˆ†å±‚é”™è¯¯å¤„ç†æœºåˆ¶
"""

import os
import re
import json
import random
import time
from pathlib import Path
from typing import List, Dict, Any, Tuple, Union
import numpy as np
import torch

# å›¾åƒå¤„ç†åº“å¯¼å…¥
try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False
    print("âš ï¸ OpenCVæœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨Pillowä½œä¸ºå›¾åƒåç«¯")

try:
    from PIL import Image
    from PIL.ExifTags import TAGS
    PILLOW_AVAILABLE = True
except ImportError:
    PILLOW_AVAILABLE = False
    print("âŒ Pillowæœªæ‰¾åˆ°ï¼Œæ— æ³•åŠ è½½å›¾åƒ")

# ComfyUIç›¸å…³å¯¼å…¥
try:
    from comfy.utils import ProgressBar
    # ComfyUIçš„ProgressBarä¸æ”¯æŒdescå‚æ•°ï¼Œéœ€è¦é€‚é…
    class ComfyUIProgressBar:
        def __init__(self, total):
            self.total = total
            self.pbar = ProgressBar(total)
        def update(self, value, desc=None):
            if desc:
                print(f"{desc}: {value}/{self.total}")
            self.pbar.update(value)
except ImportError:
    # å¦‚æœä¸åœ¨ComfyUIç¯å¢ƒä¸­ï¼Œæä¾›ç®€å•çš„æ›¿ä»£
    class ComfyUIProgressBar:
        def __init__(self, total):
            self.total = total
        def update(self, value, desc=None):
            if desc:
                print(f"{desc}: {value}/{self.total}")

# è‡ªç„¶æ’åºæ”¯æŒ
try:
    from natsort import natsorted
    NATSORT_AVAILABLE = True
except ImportError:
    NATSORT_AVAILABLE = False
    print("âš ï¸ å»ºè®®å®‰è£… natsort ä»¥è·å¾—æ›´å¥½çš„è‡ªç„¶æ’åº: pip install natsort")


class buding_BatchImageLoader:
    """
    æ™ºèƒ½å›¾åƒæ‰¹é‡åŠ è½½å™¨
    
    ä¸“ä¸ºAIå›¾åƒèµ„äº§ç®¡ç†è®¾è®¡ï¼Œæ”¯æŒï¼š
    - å¤§è§„æ¨¡å›¾åƒå†…å­˜ä¼˜åŒ–å¤„ç†
    - åŸºäºå…ƒæ•°æ®çš„æ™ºèƒ½ç­›é€‰
    - å·¥ä½œæµå°ºå¯¸ç²¾ç¡®åŒ¹é…
    - æ™ºèƒ½æ˜ å°„å’Œé”™è¯¯æ¢å¤
    """
    
    # é™æ€ç¼“å­˜ï¼Œç”¨äºå­˜å‚¨å·²æ‰«æçš„è·¯å¾„å’Œå…ƒæ•°æ®
    cache: Dict[str, Any] = {}
    
    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰è¾“å…¥å‚æ•°"""
        inputs = {
            "required": {
                "directory_path": ("STRING", {"default": "", "multiline": False, "tooltip": "è¦æ‰«æçš„èµ„äº§åº“æ ¹ç›®å½•è·¯å¾„"}),
                "image_extension": ([".png|.jpg|.jpeg", ".png", ".jpg", ".jpeg", "any"], 
                                   {"default": ".png|.jpg|.jpeg", "tooltip": "ä½¿ç”¨ '|' åˆ†éš”ã€‚'any' åŒ¹é…æ‰€æœ‰æ ¼å¼ã€‚"}),
                "keywords": ("STRING", {"default": "", "multiline": True, "tooltip": "æ­£å‘åŒ¹é…å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼ˆæˆ–å…³ç³»ï¼‰"}),
                "similarity_threshold": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.1, "tooltip": "æ¨¡ç³ŠåŒ¹é…çš„æœ€ä½ç›¸ä¼¼åº¦è¦æ±‚"}),
                "debug_mode": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨è°ƒè¯•è¾“å‡ºæ¨¡å¼"}),
            },
            "optional": {
                # å›¾åƒç‰¹æœ‰åŠŸèƒ½
                "metadata_keywords": ("STRING", {"default": "", "multiline": True, "tooltip": "åœ¨PNGå…ƒæ•°æ®ä¸­æœç´¢å…³é”®è¯"}),
                "min_resolution": ("INT", {"default": 512, "min": 0, "max": 32768, "step": 64, "tooltip": "å›¾åƒæœ€å°å®½åº¦/é«˜åº¦è¦æ±‚ï¼Œæœ€å¤§32768åƒç´ "}),
                "max_resolution": ("INT", {"default": 2048, "min": 0, "max": 32768, "step": 64, "tooltip": "å›¾åƒæœ€å¤§å®½åº¦/é«˜åº¦é™åˆ¶ï¼Œæœ€å¤§32768åƒç´ "}),
                "aspect_ratio": (["any", "1:1", "16:9", "4:3", "3:2", "portrait"], {"default": "any", "tooltip": "å®½é«˜æ¯”ç­›é€‰"}),
                
                # æ€§èƒ½ä¸é²æ£’æ€§
                "fast_scan_mode": ("BOOLEAN", {"default": True, "tooltip": "ä¸¤éæ‰«æï¼šå…ˆå…ƒæ•°æ®ç­›é€‰ï¼Œå†åŠ è½½åƒç´ "}),
                "scan_max_depth": ("INT", {"default": 10, "min": 1, "max": 100, "step": 1, "tooltip": "ç›®å½•æ‰«ææœ€å¤§æ·±åº¦ï¼Œ1è¡¨ç¤ºåªæ‰«æå½“å‰ç›®å½•"}),
                "image_backend": (["OpenCV", "Pillow"], {"default": "OpenCV" if OPENCV_AVAILABLE else "Pillow", "tooltip": "å›¾åƒåŠ è½½åç«¯"}),
                "on_io_error": (["åœæ­¢å¹¶æŠ¥é”™", "è·³è¿‡å¹¶è­¦å‘Š"], {"default": "åœæ­¢å¹¶æŠ¥é”™", "tooltip": "æ–‡ä»¶ç¼ºå¤±ç­‰IOé”™è¯¯å¤„ç†"}),
                "on_data_error": (["è·³è¿‡å¹¶è­¦å‘Š", "åœæ­¢å¹¶æŠ¥é”™"], {"default": "è·³è¿‡å¹¶è­¦å‘Š", "tooltip": "æ–‡ä»¶æŸåç­‰æ•°æ®é”™è¯¯å¤„ç†"}),
                "max_filesize_kb": ("INT", {"default": 50000, "min": 0, "max": 10485760, "step": 1024, "tooltip": "æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶(KB)ï¼Œæœ€å¤§10485760KB(10GB)"}),
                "min_filesize_kb": ("INT", {"default": 50, "min": 0, "max": 10485760, "step": 1024, "tooltip": "æœ€å°æ–‡ä»¶å¤§å°é™åˆ¶(KB)ï¼Œæœ€å¤§10485760KB(10GB)"}),
                
                # é€šç”¨åŠŸèƒ½ï¼ˆä»æ–‡æœ¬åŠ è½½å™¨ç§»æ¤ï¼‰
                "enable_mapping": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å¯ç”¨è¯­ä¹‰æ˜ å°„"}),
                "mapping_json": ("STRING", {"default": "{\n  \"temp_01\": \"ä¸»è§’A\",\n  \"temp_02\": \"ä¸»è§’B\",\n  \"draft\": \"è‰ç¨¿ç‰ˆ\",\n  \"final\": \"æœ€ç»ˆç‰ˆ\"\n}", "multiline": True, "tooltip": "JSONæ ¼å¼çš„æ˜ å°„è¡¨"}),
                "enable_negative_filter": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨åå‘åŒ¹é…æ¨¡å¼"}),
                "negative_keywords": ("STRING", {"default": "", "multiline": True, "tooltip": "åå‘æ’é™¤å…³é”®è¯"}),
                "enable_time_filter": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨æ—¶é—´æˆ³ç­›é€‰åŠŸèƒ½"}),
                "min_age_days": ("STRING", {"default": "0.0", "tooltip": "æ–‡ä»¶æœ€å°å¹´é¾„ï¼ˆå¤©ï¼‰ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶"}),
                "max_age_days": ("STRING", {"default": "0.0", "tooltip": "æ–‡ä»¶æœ€å¤§å¹´é¾„ï¼ˆå¤©ï¼‰ï¼Œ0è¡¨ç¤ºä»Šå¤©"}),
                "date_filter_mode": (["ä¿®æ”¹æ—¶é—´", "åˆ›å»ºæ—¶é—´"], {"default": "ä¿®æ”¹æ—¶é—´", "tooltip": "æ—¶é—´æˆ³ç­›é€‰ç±»å‹"}),
                "sort_mode": (["æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)", "æ–‡ä»¶å(å­—æ¯)", "ä¿®æ”¹æ—¶é—´(æ–°åˆ°æ—§)", "ä¿®æ”¹æ—¶é—´(æ—§åˆ°æ–°)", "æ–‡ä»¶å¤§å°(å¤§åˆ°å°)", "æ–‡ä»¶å¤§å°(å°åˆ°å¤§)", "éšæœºæ’åº"], {"default": "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)", "tooltip": "æ–‡ä»¶æ’åºæ–¹å¼"}),
                "random_selection": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦éšæœºé€‰æ‹©æ–‡ä»¶"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xFFFFFFFFFFFFFFFF, "tooltip": "éšæœºç§å­ï¼Œ0è¡¨ç¤ºè‡ªåŠ¨ç”Ÿæˆ"}),
                "file_limit": ("INT", {"default": 0, "min": 0, "step": 1, "tooltip": "è¾“å‡ºåˆ—è¡¨æœ€å¤§æ–‡ä»¶æ•°é‡ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶"}),
                "start_index": ("INT", {"default": 0, "min": 0, "step": 1, "tooltip": "ä»åˆ—è¡¨çš„å“ªä¸ªç´¢å¼•å¼€å§‹è¾“å‡º"}),
                "select_index": ("INT", {"default": -1, "min": -1, "step": 1, "tooltip": "å¼ºåˆ¶é€‰ä¸­åˆ—è¡¨ä¸­çš„ç‰¹å®šç´¢å¼•æ–‡ä»¶ï¼Œ-1ç¦ç”¨"}),
            }
        }
        return inputs

    RETURN_TYPES = ("IMAGE", "IMAGE", "STRING", "INT", "STRING", "INT", "INT")
    RETURN_NAMES = ("image_list", "selected_image", "file_paths", "file_count", "error_log", "width", "height")
    OUTPUT_IS_LIST = (True, False, False, False, False, False, False)  # image_listè¿”å›åˆ—è¡¨æ ¼å¼
    FUNCTION = "load_batch"
    CATEGORY = "buding_Tools/File_Assets"
    
    @classmethod
    def IS_CHANGED(cls, directory_path, image_extension, keywords, similarity_threshold, debug_mode=False, **kwargs):
        """æ£€æŸ¥è¾“å…¥æ˜¯å¦æ”¹å˜"""
        param_string = f"{directory_path}_{image_extension}_{keywords}_{similarity_threshold}_{str(kwargs)}"
        return hash(param_string)

    def load_batch(self, directory_path: str, keywords: str, image_extension: str = ".png|.jpg|.jpeg", 
                   similarity_threshold: float = 0.7, debug_mode: bool = False, 
                   metadata_keywords: str = "", min_resolution: int = 512, max_resolution: int = 2048, 
                   aspect_ratio: str = "any", fast_scan_mode: bool = True, scan_max_depth: int = 10,
                   image_backend: str = "OpenCV", on_io_error: str = "åœæ­¢å¹¶æŠ¥é”™", on_data_error: str = "è·³è¿‡å¹¶è­¦å‘Š", 
                   max_filesize_kb: int = 50000, min_filesize_kb: int = 50, enable_mapping: bool = False, 
                   mapping_json: str = "", enable_negative_filter: bool = False, negative_keywords: str = "", 
                   enable_time_filter: bool = False, min_age_days: str = "0.0", max_age_days: str = "0.0", 
                   date_filter_mode: str = "ä¿®æ”¹æ—¶é—´", sort_mode: str = "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)", 
                   random_selection: bool = False, seed: int = 0, file_limit: int = 0, 
                   start_index: int = 0, select_index: int = -1, **kwargs: Any) -> Tuple[torch.Tensor, str, int, int]:
        """æ™ºèƒ½å›¾åƒæ‰¹é‡åŠ è½½ä¸»å‡½æ•°"""
        
        # å‚æ•°éªŒè¯ï¼šå¤„ç†å­—ç¬¦ä¸²è½¬æ¢ä¸ºfloat
        try:
            min_age_days = float(min_age_days) if min_age_days else 0.0
        except (ValueError, TypeError):
            min_age_days = 0.0
            
        try:
            max_age_days = float(max_age_days) if max_age_days else 0.0
        except (ValueError, TypeError):
            max_age_days = 0.0
        
        # æ£€æŸ¥ä¾èµ–
        if not PILLOW_AVAILABLE:
            raise ImportError("Pillowæœªå®‰è£…ï¼Œæ— æ³•åŠ è½½å›¾åƒã€‚è¯·å®‰è£…: pip install Pillow")
        
        if image_backend == "OpenCV" and not OPENCV_AVAILABLE:
            if debug_mode:
                print("âš ï¸ OpenCVä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°Pillowåç«¯")
            image_backend = "Pillow"
        
        # åˆå§‹åŒ–è¿›åº¦æ¡å’Œé”™è¯¯æ—¥å¿—
        pbar = ComfyUIProgressBar(100)
        pbar.update(5, desc="åˆå§‹åŒ–å›¾åƒåŠ è½½å™¨...")
        error_log = []
        
        try:
            # 1. ä¸¤éæ‰«ææœºåˆ¶ï¼šç¬¬ä¸€éæ‰«æå…ƒæ•°æ®
            all_file_infos = self._scan_and_filter_metadata(
                directory_path, image_extension, keywords, similarity_threshold, 
                metadata_keywords, min_resolution, max_resolution, aspect_ratio,
                fast_scan_mode, scan_max_depth, image_backend, on_io_error, on_data_error,
                max_filesize_kb, min_filesize_kb, enable_mapping, mapping_json,
                enable_negative_filter, negative_keywords, enable_time_filter,
                min_age_days, max_age_days, date_filter_mode, debug_mode, error_log
            )
            pbar.update(70, desc=f"ç¬¬ä¸€éæ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(all_file_infos)} ä¸ªåŒ¹é…æ–‡ä»¶")
            
            # 2. åº”ç”¨æ’åºå’Œé™åˆ¶
            final_files = self._apply_limits_and_selection(
                all_file_infos, sort_mode, random_selection, seed, 
                file_limit, start_index, select_index, debug_mode
            )
            pbar.update(80, desc=f"æ’åºå’Œé™åˆ¶å®Œæˆï¼Œæœ€ç»ˆè¾“å‡º {len(final_files)} ä¸ªæ–‡ä»¶")
            
            # 3. å‡†å¤‡è¾“å‡ºæ•°æ®
            all_paths_list = []
            for f in final_files:
                original_path = f.get('original_path', f['path'])
                all_paths_list.append(original_path)
            
            file_count = len(all_paths_list)
            error_log_json = json.dumps(error_log, ensure_ascii=False)
            
            # 4. ç¬¬äºŒéæ‰«æï¼šåŠ è½½æ‰€æœ‰æœ€ç»ˆé€‰ä¸­çš„å›¾åƒï¼ˆè¿”å›åˆ—è¡¨ï¼‰
            image_list, selected_image, selected_path, width, height = self._load_all_images(
                final_files, image_backend, debug_mode, error_log
            )
            pbar.update(100, desc="å›¾åƒåŠ è½½å®Œæˆ")
            
            if debug_mode:
                print(f"ğŸ‰ æ™ºèƒ½å›¾åƒåŠ è½½å®Œæˆ: {file_count} ä¸ªæ–‡ä»¶")
                print(f"ğŸ“¸ å·²åŠ è½½ {len(image_list)} ä¸ªå›¾åƒ")
                if selected_path:
                    print(f"ğŸ“¸ é¦–é€‰å›¾åƒ: {os.path.basename(selected_path)} ({width}x{height})")
                if error_log:
                    print(f"âš ï¸ é”™è¯¯æ—¥å¿—: {len(error_log)} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥")

            return (image_list, selected_image, all_paths_list, file_count, error_log_json, width, height)
            
        except Exception as e:
            error_msg = f"âŒ æ™ºèƒ½å›¾åƒåŠ è½½å¤±è´¥: {str(e)}"
            if debug_mode:
                print(error_msg)
                import traceback
                traceback.print_exc()
            raise Exception(error_msg)

    def _scan_and_filter_metadata(self, root_dir: str, image_extension: str, keywords: str, 
                                 similarity_threshold: float, metadata_keywords: str, 
                                 min_resolution: int, max_resolution: int, aspect_ratio: str,
                                 fast_scan_mode: bool, scan_max_depth: int, image_backend: str, on_io_error: str, 
                                 on_data_error: str, max_filesize_kb: int, min_filesize_kb: int,
                                 enable_mapping: bool, mapping_json: str, enable_negative_filter: bool,
                                 negative_keywords: str, enable_time_filter: bool, min_age_days: float,
                                 max_age_days: float, date_filter_mode: str, debug_mode: bool, 
                                 error_log: List[str]) -> List[Dict]:
        """ç¬¬ä¸€éæ‰«æï¼šå¿«é€Ÿè¯»å–æ–‡ä»¶å¤´å’Œå…ƒæ•°æ®è¿›è¡Œç­›é€‰"""
        
        # è§£æå›¾åƒæ‰©å±•å
        if image_extension == "any":
            extensions = None  # ä¸é™åˆ¶æ‰©å±•å
        else:
            extensions = [ext.strip() for ext in image_extension.split('|') if ext.strip()]
        
        # è·å–åˆå§‹æ–‡ä»¶åˆ—è¡¨
        all_files = self._get_initial_file_list(root_dir, extensions, debug_mode, scan_max_depth)
        
        if debug_mode:
            print(f"ğŸ” åˆå§‹æ‰«ææ‰¾åˆ° {len(all_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        # æ™ºèƒ½æ˜ å°„å¤„ç†
        if enable_mapping:
            all_files = self._apply_semantic_mapping(all_files, mapping_json, debug_mode)
            if debug_mode:
                print(f"ğŸ—ºï¸ æ™ºèƒ½æ˜ å°„å¤„ç†å®Œæˆ")
        
        filtered_list = []
        
        for file_info in all_files:
            file_path = file_info['path']
            
            try:
                # --- é˜¶æ®µ1: æ–‡ä»¶å¤§å°å’ŒIOæ£€æŸ¥ ---
                if not self._check_filesize_limits(file_path, min_filesize_kb, max_filesize_kb):
                    continue
                
                # --- é˜¶æ®µ2: å¿«é€Ÿè¯»å–å›¾åƒå¤´ä¿¡æ¯ ---
                image_info = self._extract_image_metadata_fast(file_path, image_backend, debug_mode)
                if not image_info:
                    continue
                
                # åˆå¹¶åŸºç¡€ä¿¡æ¯å’Œå›¾åƒä¿¡æ¯
                file_info.update(image_info)
                
                # --- é˜¶æ®µ3: åº”ç”¨æ‰€æœ‰ç­›é€‰æ¡ä»¶ ---
                
                # å…³é”®è¯ç­›é€‰
                if keywords.strip() and not self._check_keywords_match(file_info, keywords, similarity_threshold):
                    continue
                
                # åˆ†è¾¨ç‡ç­›é€‰
                if not self._check_resolution_limits(file_info, min_resolution, max_resolution):
                    continue
                
                # å®½é«˜æ¯”ç­›é€‰
                if not self._check_aspect_ratio(file_info, aspect_ratio):
                    continue
                
                # å…ƒæ•°æ®å…³é”®è¯ç­›é€‰
                if metadata_keywords.strip() and not self._check_metadata_keywords(file_info, metadata_keywords):
                    continue
                
                filtered_list.append(file_info)
                
            except FileNotFoundError as e:
                if on_io_error == "åœæ­¢å¹¶æŠ¥é”™":
                    raise
                else:
                    error_log.append(f"IOé”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
                    if debug_mode:
                        print(f"âš ï¸ [IO Error] æ–‡ä»¶ç¼ºå¤±ï¼Œè·³è¿‡: {file_path}")
                    continue
            except Exception as e:
                if on_data_error == "åœæ­¢å¹¶æŠ¥é”™":
                    raise
                else:
                    error_log.append(f"æ•°æ®é”™è¯¯: {file_path} - {str(e)}")
                    if debug_mode:
                        print(f"âš ï¸ [Data Error] æ–‡ä»¶æŸåï¼Œè·³è¿‡: {file_path} ({e})")
                    continue
        
        if debug_mode:
            print(f"âœ… ç¬¬ä¸€éæ‰«æå®Œæˆï¼Œç­›é€‰åå‰©ä½™ {len(filtered_list)} ä¸ªæ–‡ä»¶")
        
        return filtered_list

    def _get_initial_file_list(self, root_dir: str, extensions: Union[List[str], None], debug_mode: bool, scan_max_depth: int) -> List[Dict]:
        """è·å–åˆå§‹æ–‡ä»¶åˆ—è¡¨"""
        # æ¸…ç†è·¯å¾„
        root_dir = root_dir.strip().strip('"\'')
        
        if not root_dir or not os.path.exists(root_dir):
            if debug_mode:
                print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {root_dir}")
            return []
        
        # æ‰«æç›®å½•
        all_files = []
        root_path = Path(root_dir)
        
        def scan_directory_with_depth(directory: str, current_depth: int):
            """é€’å½’æ‰«æç›®å½•ï¼Œæ§åˆ¶æ·±åº¦"""
            if current_depth > scan_max_depth:
                return
            
            try:
                for item in os.listdir(directory):
                    item_path = os.path.join(directory, item)
                    if os.path.isfile(item_path):
                        # æ£€æŸ¥æ‰©å±•å
                        if extensions is None or any(item_path.lower().endswith(ext.lower()) for ext in extensions):
                            file_info = {
                                'path': item_path,
                                'filename': os.path.basename(item_path),
                                'clean_name': self._clean_filename_for_match(os.path.basename(item_path))
                            }
                            all_files.append(file_info)
                    elif os.path.isdir(item_path):
                        # é€’å½’æ‰«æå­ç›®å½•
                        scan_directory_with_depth(item_path, current_depth + 1)
            except PermissionError:
                if debug_mode:
                    print(f"âš ï¸ æ— æƒé™è®¿é—®ç›®å½•: {directory}")
            except Exception as e:
                if debug_mode:
                    print(f"âš ï¸ æ‰«æç›®å½•å‡ºé”™ {directory}: {e}")
        
        # å¼€å§‹æ‰«æ
        scan_directory_with_depth(root_dir, 1)
        
        if debug_mode:
            print(f"ğŸ“ æ‰«æå®Œæˆ: æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶ (æœ€å¤§æ·±åº¦: {scan_max_depth})")
        
        if debug_mode:
            print(f"ğŸ“ ç›®å½•æ‰«æå®Œæˆ: æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
        
        return all_files

    def _apply_semantic_mapping(self, files: List[Dict], mapping_json: str, debug_mode: bool) -> List[Dict]:
        """åº”ç”¨è¯­ä¹‰æ˜ å°„ï¼Œå°†æ–‡ä»¶è·¯å¾„ä¸­çš„ä»£å·æ›¿æ¢ä¸ºè§„èŒƒåŒ–å…³é”®è¯"""
        if not mapping_json or not mapping_json.strip():
            if debug_mode:
                print("âš ï¸ æ˜ å°„JSONä¸ºç©ºï¼Œè·³è¿‡è¯­ä¹‰æ˜ å°„")
            return files
        
        try:
            # è§£ææ˜ å°„JSON
            mapping_dict = json.loads(mapping_json)
            if not isinstance(mapping_dict, dict):
                if debug_mode:
                    print("âŒ æ˜ å°„JSONæ ¼å¼é”™è¯¯ï¼šå¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
                return files
            
            if debug_mode:
                print(f"ğŸ—ºï¸ åº”ç”¨è¯­ä¹‰æ˜ å°„ï¼Œå…± {len(mapping_dict)} æ¡è§„åˆ™")
                for old, new in mapping_dict.items():
                    print(f"  â€¢ {old} â†’ {new}")
            
            # å¯¹æ¯ä¸ªæ–‡ä»¶åº”ç”¨æ˜ å°„
            mapped_files = []
            for file_info in files:
                original_path = file_info['path']
                original_filename = file_info['filename']
                original_clean_name = file_info['clean_name']
                
                # åº”ç”¨æ˜ å°„åˆ°å®Œæ•´è·¯å¾„
                mapped_path = original_path
                mapped_filename = original_filename
                
                # å¯¹è·¯å¾„ä¸­çš„æ¯ä¸ªéƒ¨åˆ†åº”ç”¨æ˜ å°„
                path_parts = original_path.replace('\\', '/').split('/')
                mapped_parts = []
                
                for part in path_parts:
                    mapped_part = part
                    for old_term, new_term in mapping_dict.items():
                        if old_term in mapped_part:
                            mapped_part = mapped_part.replace(old_term, new_term)
                    mapped_parts.append(mapped_part)
                
                mapped_path = '\\'.join(mapped_parts) if '\\' in original_path else '/'.join(mapped_parts)
                
                # å¯¹æ–‡ä»¶ååº”ç”¨æ˜ å°„
                for old_term, new_term in mapping_dict.items():
                    if old_term in mapped_filename:
                        mapped_filename = mapped_filename.replace(old_term, new_term)
                
                # é‡æ–°è®¡ç®—æ˜ å°„åçš„clean_name
                mapped_clean_name = self._clean_filename_for_match(mapped_filename)
                
                # åˆ›å»ºæ–°çš„æ–‡ä»¶ä¿¡æ¯å¯¹è±¡
                mapped_file_info = file_info.copy()
                mapped_file_info.update({
                    'path': mapped_path,
                    'filename': mapped_filename,
                    'clean_name': mapped_clean_name,
                    'original_path': original_path,  # ä¿ç•™åŸå§‹è·¯å¾„ç”¨äºæœ€ç»ˆè¾“å‡º
                })
                
                mapped_files.append(mapped_file_info)
                
                if debug_mode and (mapped_path != original_path or mapped_filename != original_filename):
                    print(f"  ğŸ”„ {original_path} â†’ {mapped_path}")
            
            if debug_mode:
                print(f"âœ… è¯­ä¹‰æ˜ å°„å®Œæˆï¼Œå¤„ç†äº† {len(mapped_files)} ä¸ªæ–‡ä»¶")
            
            return mapped_files
            
        except json.JSONDecodeError as e:
            if debug_mode:
                print(f"âŒ æ˜ å°„JSONè§£æå¤±è´¥: {e}")
            return files
        except Exception as e:
            if debug_mode:
                print(f"âŒ è¯­ä¹‰æ˜ å°„åº”ç”¨å¤±è´¥: {e}")
            return files

    def _check_keywords_match(self, file_info: Dict, keywords_str: str, threshold: float) -> bool:
        """æ£€æŸ¥å…³é”®è¯åŒ¹é…"""
        if not keywords_str.strip():
            return True
        
        # è§£æå…³é”®è¯åˆ—è¡¨
        keywords = [kw.strip().lower() for kw in keywords_str.split() if kw.strip()]
        clean_filename = file_info.get('clean_name', '').lower()
        
        for keyword in keywords:
            if not keyword:
                continue
            
            # ç²¾ç¡®åŒ¹é…
            if keyword == clean_filename:
                return True
            
            # åŒ…å«åŒ¹é…
            if keyword in clean_filename or clean_filename in keyword:
                return True
            
            # æ¨¡ç³ŠåŒ¹é…
            if threshold > 0:
                import difflib
                similarity = difflib.SequenceMatcher(None, keyword, clean_filename).ratio()
                if similarity >= threshold:
                    return True
        
        return False

    def _check_filesize_limits(self, file_path: str, min_kb: int, max_kb: int) -> bool:
        """æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶"""
        try:
            file_size_bytes = os.path.getsize(file_path)
            file_size_kb = file_size_bytes // 1024
            
            if min_kb > 0 and file_size_kb < min_kb:
                return False
            if max_kb > 0 and file_size_kb > max_kb:
                return False
            
            return True
        except OSError:
            return False

    def _extract_image_metadata_fast(self, file_path: str, backend: str, debug_mode: bool) -> Dict[str, Any]:
        """å¿«é€Ÿæå–å›¾åƒå…ƒæ•°æ®ï¼ˆä¸åŠ è½½åƒç´ æ•°æ®ï¼‰"""
        try:
            if backend == "OpenCV":
                return self._extract_metadata_opencv_fast(file_path, debug_mode)
            else:
                return self._extract_metadata_pillow_fast(file_path, debug_mode)
        except Exception as e:
            if debug_mode:
                print(f"âš ï¸ å…ƒæ•°æ®æå–å¤±è´¥ {file_path}: {e}")
            return {}

    def _extract_metadata_opencv_fast(self, file_path: str, debug_mode: bool) -> Dict[str, Any]:
        """OpenCVå¿«é€Ÿå…ƒæ•°æ®æå–"""
        try:
            # ä½¿ç”¨cv2.imreadåªè¯»å–å¤´ä¿¡æ¯
            img = cv2.imread(file_path, cv2.IMREAD_IGNORE_ORIENTATION | cv2.IMREAD_UNCHANGED)
            if img is None:
                return {}
            
            height, width = img.shape[:2]
            channels = img.shape[2] if len(img.shape) > 2 else 1
            
            return {
                'width': width,
                'height': height,
                'channels': channels,
                'metadata_text': '',  # OpenCVä¸è¯»å–PNGå…ƒæ•°æ®
            }
        except Exception as e:
            if debug_mode:
                print(f"OpenCVå…ƒæ•°æ®æå–å¤±è´¥: {e}")
            return {}

    def _extract_metadata_pillow_fast(self, file_path: str, debug_mode: bool) -> Dict[str, Any]:
        """Pillowå¿«é€Ÿå…ƒæ•°æ®æå–"""
        try:
            with Image.open(file_path) as img:
                # åªè¯»å–å°ºå¯¸ä¿¡æ¯ï¼Œä¸åŠ è½½åƒç´ æ•°æ®
                width, height = img.size
                channels = len(img.getbands()) if hasattr(img, 'getbands') else 3
                
                # æå–PNGå…ƒæ•°æ®
                metadata_text = ''
                if hasattr(img, 'info') and img.info:
                    for key, value in img.info.items():
                        if key.lower() in ['parameters', 'prompt', 'negative_prompt', 'description']:
                            metadata_text += str(value) + ' '
                
                return {
                    'width': width,
                    'height': height,
                    'channels': channels,
                    'metadata_text': metadata_text.strip(),
                }
        except Exception as e:
            if debug_mode:
                print(f"Pillowå…ƒæ•°æ®æå–å¤±è´¥: {e}")
            return {}

    def _check_resolution_limits(self, file_info: Dict, min_res: int, max_res: int) -> bool:
        """æ£€æŸ¥åˆ†è¾¨ç‡é™åˆ¶"""
        width = file_info.get('width', 0)
        height = file_info.get('height', 0)
        
        if width == 0 or height == 0:
            return False
        
        if min_res > 0 and (width < min_res or height < min_res):
            return False
        
        if max_res > 0 and (width > max_res or height > max_res):
            return False
        
        return True

    def _check_aspect_ratio(self, file_info: Dict, target_ratio: str) -> bool:
        """æ£€æŸ¥å®½é«˜æ¯”"""
        if target_ratio == "any":
            return True
        
        width = file_info.get('width', 0)
        height = file_info.get('height', 0)
        
        if width == 0 or height == 0:
            return False
        
        if target_ratio == "portrait":
            return height > width
        
        # é¢„å®šä¹‰å®½é«˜æ¯”
        ratios = {
            "1:1": 1.0,
            "16:9": 16.0 / 9.0,
            "4:3": 4.0 / 3.0,
            "3:2": 3.0 / 2.0,
        }
        
        expected = ratios.get(target_ratio)
        if expected is None:
            return True
        
        actual = width / height
        # å…è®¸10%çš„è¯¯å·®
        return abs(actual - expected) < 0.1

    def _check_metadata_keywords(self, file_info: Dict, keywords_str: str) -> bool:
        """æ£€æŸ¥å…ƒæ•°æ®å…³é”®è¯"""
        if not keywords_str.strip():
            return True
        
        metadata_text = file_info.get('metadata_text', '').lower()
        keywords = [kw.strip().lower() for kw in keywords_str.split() if kw.strip()]
        
        for keyword in keywords:
            if keyword in metadata_text:
                return True
        
        return False

    def _clean_filename_for_match(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…"""
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        name = os.path.splitext(filename)[0]
        
        # ç§»é™¤å¸¸è§çš„ç‰ˆæœ¬å·å’Œåˆ†éš”ç¬¦
        name = re.sub(r'[_\-\s]+', ' ', name)
        
        # ç§»é™¤æ•°å­—ç‰ˆæœ¬æ ‡è¯†
        name = re.sub(r'[ _]?[vV][0-9]+', '', name)
        
        # ç§»é™¤çº¯æ•°å­—ï¼ˆä½†ä¿ç•™ä¸­æ–‡æ•°å­—ï¼‰
        name = re.sub(r'\b\d+\b', '', name)
        
        # åªä¿ç•™å­—æ¯ã€ä¸­æ–‡ã€ç©ºæ ¼ã€åŸºæœ¬æ ‡ç‚¹
        name = re.sub(r'[^\w\u4e00-\u9fff\s\-_\.\(\)\[\]]', '', name)
        
        return name.lower().strip()

    def _apply_limits_and_selection(self, files: List[Dict], sort_mode: str, random_selection: bool, 
                                  seed: int, file_limit: int, start_index: int, select_index: int, 
                                  debug: bool) -> List[Dict]:
        """åº”ç”¨æ’åºã€é™åˆ¶å’Œé€‰æ‹©é€»è¾‘"""
        if not files:
            return []
        
        # æ’åº
        sorted_files = self._apply_smart_sorting(files, sort_mode)
        
        # éšæœºé€‰æ‹©
        if random_selection:
            if seed != 0:
                random.seed(seed)
            random.shuffle(sorted_files)
        
        # ç´¢å¼•é€‰æ‹©
        if select_index >= 0 and select_index < len(sorted_files):
            return [sorted_files[select_index]]
        
        # åº”ç”¨é™åˆ¶
        if start_index >= 0:
            sorted_files = sorted_files[start_index:]
        
        if file_limit > 0:
            sorted_files = sorted_files[:file_limit]
        
        return sorted_files

    def _apply_smart_sorting(self, files: List[Dict], sort_mode: str) -> List[Dict]:
        """æ™ºèƒ½æ’åº"""
        if not files:
            return []
        
        if sort_mode == "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)":
            if NATSORT_AVAILABLE:
                return natsorted(files, key=lambda x: x['filename'])
            else:
                return sorted(files, key=lambda x: x['filename'])
        
        elif sort_mode == "æ–‡ä»¶å(å­—æ¯)":
            return sorted(files, key=lambda x: x['filename'].lower())
        
        elif sort_mode == "ä¿®æ”¹æ—¶é—´(æ–°åˆ°æ—§)":
            return sorted(files, key=lambda x: x['mtime'], reverse=True)
        
        elif sort_mode == "ä¿®æ”¹æ—¶é—´(æ—§åˆ°æ–°)":
            return sorted(files, key=lambda x: x['mtime'])
        
        elif sort_mode == "æ–‡ä»¶å¤§å°(å¤§åˆ°å°)":
            return sorted(files, key=lambda x: x['size'], reverse=True)
        
        elif sort_mode == "æ–‡ä»¶å¤§å°(å°åˆ°å¤§)":
            return sorted(files, key=lambda x: x['size'])
        
        elif sort_mode == "éšæœºæ’åº":
            shuffled = files.copy()
            random.shuffle(shuffled)
            return shuffled
        
        else:
            return files

    def _load_all_images(self, final_files: List[Dict], backend: str, debug_mode: bool, error_log: List[str]) -> Tuple[List[torch.Tensor], torch.Tensor, str, int, int]:
        """ç¬¬äºŒéæ‰«æï¼šåŠ è½½æ‰€æœ‰æœ€ç»ˆé€‰ä¸­çš„å›¾åƒï¼ˆè¿”å›åˆ—è¡¨ï¼‰"""
        if not final_files:
            return [], torch.zeros(1, 64, 64, 3), "", 0, 0
        
        image_list = []
        selected_image = None
        selected_path = ""
        width = 0
        height = 0
        
        for idx, file_info in enumerate(final_files):
            file_path = file_info.get('original_path', file_info['path'])
            
            try:
                if backend == "OpenCV":
                    image_tensor = self._load_image_opencv(file_path, debug_mode)
                else:
                    image_tensor = self._load_image_pillow(file_path, debug_mode)
                
                image_list.append(image_tensor)
                
                # ç¬¬ä¸€å¼ å›¾ä½œä¸ºé€‰ä¸­çš„é¢„è§ˆå›¾
                if idx == 0:
                    selected_image = image_tensor
                    selected_path = file_path
                    width = file_info.get('width', 0)
                    height = file_info.get('height', 0)
                
            except Exception as e:
                error_msg = f"å›¾åƒåŠ è½½å¤±è´¥ {file_path}: {e}"
                error_log.append(error_msg)
                if debug_mode:
                    print(f"ğŸš¨ [Load Error] {error_msg}")
                continue
        
        # å¦‚æœæ²¡æœ‰åŠ è½½ä»»ä½•å›¾åƒï¼Œè¿”å›ç©º
        if not image_list:
            return [], torch.zeros(1, 64, 64, 3), "", 0, 0
        
        # ç¡®ä¿selected_imageä¸ä¸ºç©º
        if selected_image is None:
            selected_image = image_list[0]
        
        return image_list, selected_image, selected_path, width, height

    def _load_selected_image(self, final_files: List[Dict], backend: str, debug_mode: bool, error_log: List[str]) -> Tuple[torch.Tensor, str, int, int]:
        """ç¬¬äºŒéæ‰«æï¼šåŠ è½½æœ€ç»ˆé€‰ä¸­çš„å›¾åƒ"""
        if not final_files:
            return torch.zeros(1, 64, 64, 3), "", 0, 0
        
        selected_file = final_files[0]
        selected_path = selected_file.get('original_path', selected_file['path'])
        width = selected_file.get('width', 0)
        height = selected_file.get('height', 0)
        
        try:
            if backend == "OpenCV":
                image_tensor = self._load_image_opencv(selected_path, debug_mode)
            else:
                image_tensor = self._load_image_pillow(selected_path, debug_mode)
            
            return image_tensor, selected_path, width, height
            
        except Exception as e:
            error_msg = f"æœ€ç»ˆå›¾åƒåŠ è½½å¤±è´¥ {selected_path}: {e}"
            error_log.append(error_msg)
            if debug_mode:
                print(f"ğŸš¨ [Final Load Error] {error_msg}")
            
            # è¿”å›ç©ºå¼ é‡ï¼Œé˜²æ­¢å·¥ä½œæµä¸­æ–­
            return torch.zeros(1, 64, 64, 3), selected_path, 0, 0

    def _load_image_opencv(self, file_path: str, debug_mode: bool) -> torch.Tensor:
        """ä½¿ç”¨OpenCVåŠ è½½å›¾åƒ"""
        try:
            img = cv2.imread(file_path, cv2.IMREAD_COLOR)
            if img is None:
                raise ValueError("OpenCVæ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
            
            # BGRè½¬RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # è½¬æ¢ä¸ºå¼ é‡
            img = img.astype(np.float32) / 255.0
            tensor = torch.from_numpy(img)[None,]  # æ·»åŠ batchç»´åº¦
            
            return tensor
            
        except Exception as e:
            if debug_mode:
                print(f"OpenCVåŠ è½½å¤±è´¥: {e}")
            raise

    def _load_image_pillow(self, file_path: str, debug_mode: bool) -> torch.Tensor:
        """ä½¿ç”¨PillowåŠ è½½å›¾åƒ"""
        try:
            with Image.open(file_path) as img:
                # è½¬æ¢ä¸ºRGB
                img = img.convert("RGB")
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_array = np.array(img).astype(np.float32) / 255.0
                
                # è½¬æ¢ä¸ºå¼ é‡
                tensor = torch.from_numpy(img_array)[None,]  # æ·»åŠ batchç»´åº¦
                
                return tensor
                
        except Exception as e:
            if debug_mode:
                print(f"PillowåŠ è½½å¤±è´¥: {e}")
            raise

# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "buding_BatchImageLoader": buding_BatchImageLoader,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "buding_BatchImageLoader": "ğŸ–¼ï¸ buding_BatchImageLoader (æ‰¹é‡å›¾åƒåŠ è½½å™¨)",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']
