"""
buding_SmartAudioLoader - æ™ºèƒ½éŸ³é¢‘æ‰¹é‡åŠ è½½å™¨
ç‰ˆæœ¬: v1.0.0
åŠŸèƒ½: éŸ³é¢‘æ—¶é•¿ç­›é€‰ã€æ ¼å¼æ ‡å‡†åŒ–ã€å…ƒæ•°æ®å¿«é€Ÿç­›é€‰ã€è¶…é•¿éŸ³é¢‘å¤„ç†ç­–ç•¥
ä¾èµ–: mutagen (å…ƒæ•°æ®è¯»å–), torchaudio (æ³¢å½¢åŠ è½½)
"""

import os
import json
import random
import hashlib
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

# æ ¸å¿ƒä¾èµ–
try:
    from mutagen import File as MutagenFile
    MUTAGEN_AVAILABLE = True
except ImportError:
    MUTAGEN_AVAILABLE = False
    print("âš ï¸ mutagenæœªå®‰è£…ï¼ŒéŸ³é¢‘å…ƒæ•°æ®åŠŸèƒ½å°†å—é™")

try:
    import torchaudio
    TORCHAUDIO_AVAILABLE = True
except ImportError:
    TORCHAUDIO_AVAILABLE = False
    print("âš ï¸ torchaudioæœªå®‰è£…ï¼ŒéŸ³é¢‘åŠ è½½åŠŸèƒ½å°†å—é™")

import torch
import numpy as np

# ComfyUIç›¸å…³å¯¼å…¥
try:
    from comfy.utils import ProgressBar
    # ComfyUIçš„ProgressBarä¸æ”¯æŒdescå‚æ•°ï¼Œéœ€è¦é€‚é…
    class ComfyUIProgressBar:
        def __init__(self, total):
            self.total = total
            self.pbar = ProgressBar(total)
        def update(self, value, desc=None):
            if desc:
                print(f"{desc}: {value}/{self.total}")
            self.pbar.update(value)
except ImportError:
    # å¦‚æœä¸åœ¨ComfyUIç¯å¢ƒä¸­ï¼Œæä¾›ç®€å•çš„æ›¿ä»£
    class ComfyUIProgressBar:
        def __init__(self, total):
            self.total = total
        def update(self, value, desc=None):
            if desc:
                print(f"{desc}: {value}/{self.total}")

def audio_to_tensor(waveform: torch.Tensor, samplerate: int) -> torch.Tensor:
    """torchaudio waveform to ComfyUI/PyTorch Tensor"""
    # ç¡®ä¿æ³¢å½¢æ ¼å¼ä¸º [1, channels, samples]
    if waveform.dim() == 2:  # [channels, samples]
        waveform = waveform.unsqueeze(0)  # [1, channels, samples]
    elif waveform.dim() == 1:  # [samples]
        waveform = waveform.unsqueeze(0).unsqueeze(0)  # [1, 1, samples]
    return waveform

class buding_SmartAudioBatchLoader:
    """æ™ºèƒ½éŸ³é¢‘æ‰¹é‡åŠ è½½å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰è¾“å…¥å‚æ•°"""
        inputs = {
            "required": {
                "directory_path": ("STRING", {"default": "", "multiline": False, "tooltip": "è¦æ‰«æçš„éŸ³é¢‘æ–‡ä»¶ç›®å½•è·¯å¾„"}),
                "audio_extension": (
                    [".wav|.mp3|.flac", ".wav", ".mp3", ".flac", "any"], 
                    {"default": ".wav|.mp3|.flac", "tooltip": "éŸ³é¢‘æ ¼å¼ç­›é€‰ï¼Œä½¿ç”¨ '|' åˆ†éš”ã€‚'any' åŒ¹é…æ‰€æœ‰æ ¼å¼"}
                ),
                "keywords": ("STRING", {"default": "", "multiline": True, "tooltip": "æ­£å‘åŒ¹é…å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼ˆæˆ–å…³ç³»ï¼‰"}),
                "similarity_threshold": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.1, "tooltip": "æ¨¡ç³ŠåŒ¹é…çš„æœ€ä½ç›¸ä¼¼åº¦è¦æ±‚"}),
                "debug_mode": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨è°ƒè¯•è¾“å‡ºæ¨¡å¼"}),
                
                # æ—¶é•¿æ§åˆ¶ (åœºæ™¯ä¸€)
                "min_duration": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 3600.0, "step": 0.1, "tooltip": "æœ€å°æ—¶é•¿(ç§’)ï¼Œæ’é™¤è¿‡çŸ­éŸ³é¢‘"}),
            },
            "optional": {
                # è¶…é•¿å¤„ç†æ€»å¼€å…³ (åœºæ™¯ä¸€æœ€ç»ˆä¼˜åŒ–)
                "enable_exceedance_handling": ("BOOLEAN", {"default": True, "tooltip": "å¯ç”¨æœ€å¤§æ—¶é•¿æ£€æŸ¥å’Œå¤„ç†"}),
                "max_duration": ("FLOAT", {"default": 20.0, "min": 0.0, "max": 3600.0, "step": 0.1, "tooltip": "æœ€å¤§æ—¶é•¿(ç§’)ï¼Œè¶…è¿‡æ­¤é˜ˆå€¼çš„æ–‡ä»¶å°†æŒ‰ç­–ç•¥å¤„ç†"}),
                "on_max_duration_exceedance": (["Filter/Skip", "Pass_Through"], {"default": "Filter/Skip", "tooltip": "è¶…é•¿éŸ³é¢‘å¤„ç†ç­–ç•¥"}),
                
                # å£°å­¦è´¨é‡ç­›é€‰
                "min_rms_db": ("FLOAT", {"default": -40.0, "min": -100.0, "max": 0.0, "step": 1.0, "tooltip": "æœ€å°RMSç”µå¹³(dB)ï¼Œæ’é™¤é™éŸ³æ–‡ä»¶"}),
                
                # æ€§èƒ½ä¸é²æ£’æ€§
                "scan_max_depth": ("INT", {"default": 10, "min": 1, "max": 100, "step": 1, "tooltip": "ç›®å½•æ‰«ææœ€å¤§æ·±åº¦ï¼Œ1è¡¨ç¤ºåªæ‰«æå½“å‰ç›®å½•"}),
                "on_io_error": (["åœæ­¢å¹¶æŠ¥é”™", "è·³è¿‡å¹¶è­¦å‘Š"], {"default": "åœæ­¢å¹¶æŠ¥é”™", "tooltip": "æ–‡ä»¶ç¼ºå¤±ç­‰IOé”™è¯¯å¤„ç†"}),
                "on_data_error": (["è·³è¿‡å¹¶è­¦å‘Š", "åœæ­¢å¹¶æŠ¥é”™"], {"default": "è·³è¿‡å¹¶è­¦å‘Š", "tooltip": "æ–‡ä»¶æŸåç­‰æ•°æ®é”™è¯¯å¤„ç†"}),
                
                # é€šç”¨åŠŸèƒ½ï¼ˆä»æ–‡æœ¬åŠ è½½å™¨ç§»æ¤ï¼‰
                "enable_mapping": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å¯ç”¨è¯­ä¹‰æ˜ å°„"}),
                "mapping_json": ("STRING", {"default": "{\n  \"temp_01\": \"è§’è‰²A\",\n  \"temp_02\": \"è§’è‰²B\",\n  \"draft\": \"è‰ç¨¿ç‰ˆ\",\n  \"final\": \"æœ€ç»ˆç‰ˆ\"\n}", "multiline": True, "tooltip": "JSONæ ¼å¼çš„æ˜ å°„è¡¨"}),
                "enable_negative_filter": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨åå‘åŒ¹é…æ¨¡å¼"}),
                "negative_keywords": ("STRING", {"default": "", "multiline": True, "tooltip": "åå‘æ’é™¤å…³é”®è¯"}),
                "enable_time_filter": ("BOOLEAN", {"default": False, "tooltip": "å¯ç”¨æ—¶é—´æˆ³ç­›é€‰åŠŸèƒ½"}),
                "min_age_days": ("STRING", {"default": "0.0", "tooltip": "æ–‡ä»¶æœ€å°å¹´é¾„ï¼ˆå¤©ï¼‰ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶"}),
                "max_age_days": ("STRING", {"default": "0.0", "tooltip": "æ–‡ä»¶æœ€å¤§å¹´é¾„ï¼ˆå¤©ï¼‰ï¼Œ0è¡¨ç¤ºä»Šå¤©"}),
                "date_filter_mode": (["ä¿®æ”¹æ—¶é—´", "åˆ›å»ºæ—¶é—´"], {"default": "ä¿®æ”¹æ—¶é—´", "tooltip": "æ—¶é—´æˆ³ç­›é€‰ç±»å‹"}),
                "sort_mode": (["æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)", "æ–‡ä»¶å(å­—æ¯)", "ä¿®æ”¹æ—¶é—´(æ–°åˆ°æ—§)", "ä¿®æ”¹æ—¶é—´(æ—§åˆ°æ–°)", "æ–‡ä»¶å¤§å°(å¤§åˆ°å°)", "æ–‡ä»¶å¤§å°(å°åˆ°å¤§)", "éšæœºæ’åº"], {"default": "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)", "tooltip": "æ–‡ä»¶æ’åºæ–¹å¼"}),
                "random_selection": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦éšæœºé€‰æ‹©æ–‡ä»¶"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xFFFFFFFFFFFFFFFF, "tooltip": "éšæœºç§å­ï¼Œ0è¡¨ç¤ºè‡ªåŠ¨ç”Ÿæˆ"}),
                "file_limit": ("INT", {"default": 0, "min": 0, "max": 10000, "step": 1, "tooltip": "è¾“å‡ºåˆ—è¡¨æœ€å¤§æ–‡ä»¶æ•°é‡ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶"}),
                "start_index": ("INT", {"default": 0, "min": 0, "step": 1, "tooltip": "ä»åˆ—è¡¨çš„å“ªä¸ªç´¢å¼•å¼€å§‹è¾“å‡º"}),
                "select_index": ("INT", {"default": -1, "min": -1, "step": 1, "tooltip": "å¼ºåˆ¶é€‰ä¸­åˆ—è¡¨ä¸­çš„ç‰¹å®šç´¢å¼•æ–‡ä»¶ï¼Œ-1ç¦ç”¨"}),
            }
        }
        return inputs
    
    RETURN_TYPES = ("AUDIO", "STRING", "STRING", "INT", "STRING", "FLOAT", "INT", "STRING")
    RETURN_NAMES = ("AUDIO_TENSOR", "SELECTED_PATH", "ALL_PATHS", "FILE_COUNT", "INFO_MAPPING_JSON", "DURATION", "SAMPLERATE", "REPORT_JSON")
    FUNCTION = "load_batch"
    CATEGORY = "buding_Tools/æ™ºèƒ½æ–‡ä»¶åŠ è½½"
    
    @classmethod
    def IS_CHANGED(cls, directory_path, audio_extension, keywords, similarity_threshold, debug_mode=False, **kwargs):
        """æ£€æŸ¥è¾“å…¥æ˜¯å¦æ”¹å˜"""
        param_string = f"{directory_path}_{audio_extension}_{keywords}_{similarity_threshold}_{str(kwargs)}"
        return hash(param_string)
    
    def load_batch(self, directory_path: str, keywords: str, audio_extension: str = ".wav|.mp3|.flac",
                   similarity_threshold: float = 0.7, debug_mode: bool = False, min_duration: float = 0.5,
                   enable_exceedance_handling: bool = True, max_duration: float = 20.0, 
                   on_max_duration_exceedance: str = "Filter/Skip", min_rms_db: float = -40.0,
                   scan_max_depth: int = 10, on_io_error: str = "åœæ­¢å¹¶æŠ¥é”™", on_data_error: str = "è·³è¿‡å¹¶è­¦å‘Š",
                   enable_mapping: bool = False, mapping_json: str = "", enable_negative_filter: bool = False,
                   negative_keywords: str = "", enable_time_filter: bool = False, min_age_days: str = "0.0",
                   max_age_days: str = "0.0", date_filter_mode: str = "ä¿®æ”¹æ—¶é—´", sort_mode: str = "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)",
                   random_selection: bool = False, seed: int = 0, file_limit: int = 0, start_index: int = 0,
                   select_index: int = -1, **kwargs: Any) -> Tuple[torch.Tensor, str, str, int, str, float, int, str]:
        """æ™ºèƒ½éŸ³é¢‘æ‰¹é‡åŠ è½½ä¸»å‡½æ•°"""
        
        # å‚æ•°éªŒè¯ï¼šå¤„ç†å­—ç¬¦ä¸²è½¬æ¢ä¸ºfloat
        try:
            min_age_days = float(min_age_days) if min_age_days else 0.0
        except (ValueError, TypeError):
            min_age_days = 0.0
            
        try:
            max_age_days = float(max_age_days) if max_age_days else 0.0
        except (ValueError, TypeError):
            max_age_days = 0.0
        
        # æ£€æŸ¥ä¾èµ–
        if not MUTAGEN_AVAILABLE:
            raise Exception("âŒ mutagenåº“æœªå®‰è£…ï¼Œæ— æ³•è¯»å–éŸ³é¢‘å…ƒæ•°æ®ã€‚è¯·å®‰è£…: pip install mutagen")
        if not TORCHAUDIO_AVAILABLE:
            raise Exception("âŒ torchaudioåº“æœªå®‰è£…ï¼Œæ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶ã€‚è¯·å®‰è£…: pip install torchaudio")
        
        # åˆå§‹åŒ–è¿›åº¦æ¡å’Œé”™è¯¯æ—¥å¿—
        pbar = ComfyUIProgressBar(100)
        pbar.update(5, desc="åˆå§‹åŒ–éŸ³é¢‘åŠ è½½å™¨...")
        error_log = []
        
        try:
            # 1. å¿«é€Ÿæ‰«æå’Œå…ƒæ•°æ®ç­›é€‰
            all_file_infos = self._scan_and_filter_metadata(
                directory_path, audio_extension, keywords, similarity_threshold,
                min_duration, enable_exceedance_handling,
                max_duration, on_max_duration_exceedance, scan_max_depth, on_io_error,
                on_data_error, enable_mapping, mapping_json, enable_negative_filter,
                negative_keywords, enable_time_filter, min_age_days, max_age_days,
                date_filter_mode, debug_mode, error_log
            )
            pbar.update(70, desc=f"ç¬¬ä¸€éæ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(all_file_infos)} ä¸ªåŒ¹é…æ–‡ä»¶")
            
            # 2. åº”ç”¨æ’åºå’Œé™åˆ¶
            final_files = self._apply_limits_and_selection(
                all_file_infos, sort_mode, random_selection, seed, 
                file_limit, start_index, select_index, debug_mode
            )
            pbar.update(85, desc=f"æ’åºå’Œé™åˆ¶å®Œæˆï¼Œæœ€ç»ˆ {len(final_files)} ä¸ªæ–‡ä»¶")
            
            # 3. å‡†å¤‡è¾“å‡ºæ•°æ®
            all_paths_list = [f['path'] for f in final_files]
            info_mapping = self._generate_info_mapping(final_files, debug_mode)
            
            # 4. åŠ è½½é€‰ä¸­çš„éŸ³é¢‘
            selected_audio, selected_path, duration, samplerate = self._load_selected_audio(
                final_files, min_rms_db, debug_mode
            )
            
            # 5. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
            report_json = self._generate_report_json(
                final_files, final_files[0] if final_files else None, 
                {
                    "initial_files": len(all_file_infos),
                    "final_count": len(final_files),
                    "filter_efficiency": f"{len(final_files)/max(len(all_file_infos), 1)*100:.1f}%" if all_file_infos else "0%"
                },
                {
                    "min_duration": min_duration,
                    "max_duration": max_duration,
                    "enable_exceedance_handling": enable_exceedance_handling,
                    "on_max_duration_exceedance": on_max_duration_exceedance
                },
                debug_mode
            )
            
            pbar.update(100, desc="éŸ³é¢‘åŠ è½½å®Œæˆ")
            
            # 6. è¿”å›ç»“æœ (ComfyUIéŸ³é¢‘æ ¼å¼)
            return (
                {"waveform": selected_audio}, 
                selected_path, 
                json.dumps(all_paths_list, ensure_ascii=False), 
                len(final_files), 
                info_mapping, 
                duration, 
                samplerate, 
                report_json
            )
            
        except Exception as e:
            error_msg = f"âŒ æ™ºèƒ½éŸ³é¢‘åŠ è½½å¤±è´¥: {str(e)}"
            if debug_mode:
                print(error_msg)
                import traceback
                traceback.print_exc()
            raise Exception(error_msg)
    
    def _scan_and_filter_metadata(self, root_dir: str, audio_extension: str, keywords: str,
                                 similarity_threshold: float, min_duration: float,
                                 enable_exceedance_handling: bool, max_duration: float,
                                 on_max_duration_exceedance: str, scan_max_depth: int, on_io_error: str,
                                 on_data_error: str, enable_mapping: bool, mapping_json: str,
                                 enable_negative_filter: bool, negative_keywords: str,
                                 enable_time_filter: bool, min_age_days: float, max_age_days: float,
                                 date_filter_mode: str, debug_mode: bool, error_log: List[str]) -> List[Dict]:
        """ç¬¬ä¸€éæ‰«æï¼šå¿«é€Ÿè¯»å–éŸ³é¢‘å…ƒæ•°æ®è¿›è¡Œç­›é€‰"""
        
        # è§£æéŸ³é¢‘æ‰©å±•å
        if audio_extension == "any":
            extensions = None  # ä¸é™åˆ¶æ‰©å±•å
        else:
            extensions = [ext.strip() for ext in audio_extension.split('|') if ext.strip()]
        
        # è·å–åˆå§‹æ–‡ä»¶åˆ—è¡¨ï¼ˆæ”¯æŒæ‰«ææ·±åº¦æ§åˆ¶ï¼‰
        all_files = []
        
        def scan_directory_with_depth(directory: str, current_depth: int):
            """é€’å½’æ‰«æç›®å½•ï¼Œæ§åˆ¶æ·±åº¦"""
            if current_depth > scan_max_depth:
                return
            
            try:
                for item in os.listdir(directory):
                    item_path = os.path.join(directory, item)
                    if os.path.isfile(item_path):
                        all_files.append(item_path)
                    elif os.path.isdir(item_path):
                        # é€’å½’æ‰«æå­ç›®å½•
                        scan_directory_with_depth(item_path, current_depth + 1)
            except PermissionError:
                if debug_mode:
                    print(f"âš ï¸ æ— æƒé™è®¿é—®ç›®å½•: {directory}")
            except Exception as e:
                if debug_mode:
                    print(f"âš ï¸ æ‰«æç›®å½•å‡ºé”™ {directory}: {e}")
        
        # å¼€å§‹æ‰«æ
        scan_directory_with_depth(root_dir, 1)
        
        if debug_mode:
            print(f"ğŸ“ æ‰«æå®Œæˆ: æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶ (æœ€å¤§æ·±åº¦: {scan_max_depth})")
        
        # æ‰©å±•åç­›é€‰
        if extensions:
            filtered_files = []
            for file_path in all_files:
                file_ext = os.path.splitext(file_path)[1].lower()
                if file_ext in extensions:
                    filtered_files.append(file_path)
            all_files = filtered_files
        
        if debug_mode:
            print(f"ğŸ“‹ æ‰©å±•åç­›é€‰å: {len(all_files)} ä¸ªæ–‡ä»¶")
        
        # å…³é”®è¯ç­›é€‰
        if keywords.strip():
            keyword_list = [kw.strip() for kw in keywords.split('\n') if kw.strip()]
            filtered_files = []
            for file_path in all_files:
                filename = os.path.basename(file_path)
                if self._match_keywords(filename, keyword_list, similarity_threshold):
                    filtered_files.append(file_path)
            all_files = filtered_files
        
        if debug_mode:
            print(f"ğŸ” å…³é”®è¯ç­›é€‰å: {len(all_files)} ä¸ªæ–‡ä»¶")
        
        # å…ƒæ•°æ®ç­›é€‰
        filtered_list = []
        for file_path in all_files:
            try:
                # é˜¶æ®µ1: å…ƒæ•°æ®è¯»å–
                audio_file = MutagenFile(file_path)
                
                if audio_file is None or not hasattr(audio_file, 'info'):
                    raise ValueError("æ— æ³•è§£æéŸ³é¢‘å…ƒæ•°æ®")
                
                # è·å–åŸºæœ¬ä¿¡æ¯
                duration = getattr(audio_file.info, 'length', 0)
                samplerate = getattr(audio_file.info, 'sample_rate', 0)
                channels = getattr(audio_file.info, 'channels', 1)
                
                if duration <= 0 or samplerate <= 0:
                    raise ValueError("æ— æ•ˆçš„éŸ³é¢‘å…ƒæ•°æ®")
                
                # é˜¶æ®µ2: åº”ç”¨ç­›é€‰è§„åˆ™
                
                # 1. æœ€å°éŸ³é¢‘æ—¶é•¿ç­›é€‰ (å§‹ç»ˆç”Ÿæ•ˆ)
                if duration < min_duration:
                    if debug_mode:
                        print(f"â­ï¸ è·³è¿‡è¿‡çŸ­éŸ³é¢‘: {os.path.basename(file_path)} ({duration:.2f}s < {min_duration}s)")
                    continue
                
                # 2. ç›®æ ‡é‡‡æ ·ç‡å’Œå£°é“æ•°ç­›é€‰
                # 3. è¶…é•¿éŸ³é¢‘å¤„ç†
                if enable_exceedance_handling and duration > max_duration:
                    if on_max_duration_exceedance == "Filter/Skip":
                        if debug_mode:
                            print(f"â­ï¸ è·³è¿‡è¶…é•¿éŸ³é¢‘: {os.path.basename(file_path)} ({duration:.2f}s > {max_duration}s)")
                        continue
                    # Pass_Through æ¨¡å¼ç»§ç»­æ‰§è¡Œ
                
                # æ”¶é›†ä¿¡æ¯
                file_info = {
                    'path': file_path,
                    'filename': os.path.basename(file_path),
                    'duration': duration,
                    'samplerate': samplerate,
                    'channels': channels,
                    'size': os.path.getsize(file_path),
                    'mtime': os.path.getmtime(file_path),
                    'ctime': os.path.getctime(file_path)
                }
                filtered_list.append(file_info)
                
            except Exception as e:
                if on_data_error == "åœæ­¢å¹¶æŠ¥é”™":
                    raise Exception(f"éŸ³é¢‘æ–‡ä»¶è§£æå¤±è´¥: {file_path} - {e}")
                else:
                    error_msg = f"âš ï¸ éŸ³é¢‘æ–‡ä»¶æŸåæˆ–æ— æ³•è§£æï¼Œè·³è¿‡: {os.path.basename(file_path)} - {e}"
                    error_log.append(error_msg)
                    if debug_mode:
                        print(error_msg)
                    continue
        
        if debug_mode:
            print(f"âœ… å…ƒæ•°æ®ç­›é€‰å®Œæˆ: {len(filtered_list)} ä¸ªæ–‡ä»¶é€šè¿‡ç­›é€‰")
        
        return filtered_list
    
    def _match_keywords(self, filename: str, keywords: List[str], threshold: float) -> bool:
        """å…³é”®è¯åŒ¹é…ï¼ˆç®€å•å®ç°ï¼‰"""
        filename_lower = filename.lower()
        for keyword in keywords:
            if keyword.lower() in filename_lower:
                return True
        return False
    
    def _apply_limits_and_selection(self, files: List[Dict], sort_mode: str, random_selection: bool,
                                   seed: int, file_limit: int, start_index: int, select_index: int,
                                   debug_mode: bool) -> List[Dict]:
        """åº”ç”¨æ’åºã€éšæœºé€‰æ‹©å’Œæ•°é‡é™åˆ¶"""
        if not files:
            return []
        
        # æ’åº
        if sort_mode == "æ–‡ä»¶å(æ•°å­—ä¼˜å…ˆ)":
            files.sort(key=lambda x: self._natural_sort_key(x['filename']))
        elif sort_mode == "æ–‡ä»¶å(å­—æ¯)":
            files.sort(key=lambda x: x['filename'].lower())
        elif sort_mode == "ä¿®æ”¹æ—¶é—´(æ–°åˆ°æ—§)":
            files.sort(key=lambda x: x['mtime'], reverse=True)
        elif sort_mode == "ä¿®æ”¹æ—¶é—´(æ—§åˆ°æ–°)":
            files.sort(key=lambda x: x['mtime'])
        elif sort_mode == "æ–‡ä»¶å¤§å°(å¤§åˆ°å°)":
            files.sort(key=lambda x: x['size'], reverse=True)
        elif sort_mode == "æ–‡ä»¶å¤§å°(å°åˆ°å¤§)":
            files.sort(key=lambda x: x['size'])
        elif sort_mode == "éšæœºæ’åº":
            if seed == 0:
                seed = random.randint(0, 2**63 - 1)
            random.seed(seed)
            random.shuffle(files)
        
        # éšæœºé€‰æ‹©
        if random_selection:
            if seed == 0:
                seed = random.randint(0, 2**63 - 1)
            random.seed(seed)
            files = [random.choice(files)] if files else []
        
        # å¼ºåˆ¶é€‰æ‹©ç‰¹å®šç´¢å¼•
        if select_index >= 0 and select_index < len(files):
            files = [files[select_index]]
        
        # åº”ç”¨æ•°é‡é™åˆ¶å’Œèµ·å§‹ç´¢å¼•
        if file_limit > 0:
            end_index = start_index + file_limit
            files = files[start_index:end_index]
        elif start_index > 0:
            files = files[start_index:]
        
        if debug_mode:
            print(f"ğŸ“Š æ’åºå’Œé™åˆ¶åº”ç”¨å®Œæˆ: æœ€ç»ˆ {len(files)} ä¸ªæ–‡ä»¶")
        
        return files
    
    def _natural_sort_key(self, filename: str) -> List:
        """è‡ªç„¶æ’åºé”®"""
        import re
        return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', filename)]
    
    def _load_selected_audio(self, final_files: List[Dict], min_rms_db: float, debug_mode: bool) -> Tuple[torch.Tensor, str, float, int]:
        """åŠ è½½é€‰ä¸­çš„éŸ³é¢‘æ–‡ä»¶"""
        if not final_files:
            return torch.zeros(1, 1, 1), "", 0.0, 0
        
        selected_file = final_files[0]
        selected_path = selected_file['path']
        
        try:
            # åŠ è½½æ³¢å½¢æ•°æ®
            waveform, sr = torchaudio.load(selected_path)
            
            # RMSæ£€æŸ¥
            if min_rms_db > -100:
                rms = torch.sqrt(torch.mean(waveform ** 2))
                rms_db = 20 * torch.log10(rms + 1e-8)
                if rms_db < min_rms_db:
                    if debug_mode:
                        print(f"âš ï¸ éŸ³é¢‘RMSè¿‡ä½: {rms_db:.1f}dB < {min_rms_db}dB")
                    # å¯ä»¥é€‰æ‹©è¿”å›é™éŸ³æˆ–è·³è¿‡ï¼Œè¿™é‡Œè¿”å›é™éŸ³
                    return torch.zeros(1, 1, 1), selected_path, selected_file['duration'], selected_file['samplerate']
            
            # è½¬æ¢ä¸ºComfyUIæ ¼å¼
            audio_tensor = audio_to_tensor(waveform, sr)
            
            return audio_tensor, selected_path, selected_file['duration'], selected_file['samplerate']
            
        except Exception as e:
            error_msg = f"ğŸš¨ æ— æ³•åŠ è½½éŸ³é¢‘æ³¢å½¢: {selected_path} - {e}"
            if debug_mode:
                print(error_msg)
            return torch.zeros(1, 1, 1), selected_path, 0.0, 0
    
    def _generate_info_mapping(self, files: List[Dict], debug_mode: bool) -> str:
        """ç”Ÿæˆä¿¡æ¯æ˜ å°„JSON"""
        if not files:
            return "{}"
        
        mapping = {}
        for i, file_info in enumerate(files):
            mapping[str(i)] = {
                "path": file_info['path'],
                "filename": file_info['filename'],
                "duration": round(file_info['duration'], 3),
                "samplerate": file_info['samplerate'],
                "channels": file_info['channels'],
                "size": file_info['size']
            }
        
        return json.dumps(mapping, ensure_ascii=False, indent=2)
    
    def _generate_report_json(self, final_files: List[Dict], selected_file: Optional[Dict],
                             filter_stats: Dict, processing_info: Dict, debug_mode: bool) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ç»Ÿè®¡æŠ¥å‘ŠJSON"""
        if not final_files:
            return json.dumps({"error": "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„éŸ³é¢‘æ–‡ä»¶"}, ensure_ascii=False)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        durations = [f['duration'] for f in final_files]
        samplerates = [f['samplerate'] for f in final_files]
        channels = [f['channels'] for f in final_files]
        
        # æ ¼å¼åˆ†å¸ƒ
        format_distribution = {}
        for f in final_files:
            ext = os.path.splitext(f['path'])[1].lower()
            format_distribution[ext] = format_distribution.get(ext, 0) + 1
        
        report = {
            "selected_file": {
                "path": selected_file['path'] if selected_file else "",
                "filename": selected_file['filename'] if selected_file else "",
                "duration": selected_file['duration'] if selected_file else 0.0,
                "samplerate": selected_file['samplerate'] if selected_file else 0,
                "channels": selected_file['channels'] if selected_file else 0,
                "size": selected_file['size'] if selected_file else 0
            },
            "statistics": {
                "total_files": len(final_files),
                "exceeded_count": sum(1 for f in final_files if f['duration'] > processing_info.get('max_duration', 20.0)),
                "total_duration": round(sum(durations), 2),
                "avg_duration": round(sum(durations) / len(durations), 2) if durations else 0.0,
                "duration_range": {
                    "min": round(min(durations), 2) if durations else 0.0,
                    "max": round(max(durations), 2) if durations else 0.0
                },
                "samplerate_distribution": {str(sr): samplerates.count(sr) for sr in set(samplerates)},
                "channel_distribution": {"mono": channels.count(1), "stereo": channels.count(2)},
                "format_distribution": format_distribution
            },
            "filter_stats": filter_stats,
            "processing_info": processing_info
        }
        
        return json.dumps(report, ensure_ascii=False, indent=2)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "buding_SmartAudioBatchLoader": buding_SmartAudioBatchLoader,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "buding_SmartAudioBatchLoader": "ğŸµ buding_SmartAudioBatchLoader (æ™ºèƒ½éŸ³é¢‘æ‰¹é‡åŠ è½½å™¨)",
}

__all__ = ["NODE_CLASS_MAPPINGS", "NODE_DISPLAY_NAME_MAPPINGS"]
